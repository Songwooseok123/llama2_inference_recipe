{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdadbabf-2451-4cb6-b7d9-a15260fe5d42",
   "metadata": {},
   "source": [
    "# pplm_llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9eca0a2-2a2c-49a4-b986-30669252c1ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: pyarrow._fs.FileInfo size changed, may indicate binary incompatibility. Expected 64 from C header, got 88 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: pyarrow._fs.FileSelector size changed, may indicate binary incompatibility. Expected 48 from C header, got 72 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /home/wooseok/miniconda3/envs/mh/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 6.1\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /home/wooseok/miniconda3/envs/mh/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda113_nocublaslt.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wooseok/miniconda3/envs/mh/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='2'\n",
    "from evaluate import load\n",
    "import argparse\n",
    "import json\n",
    "from operator import add\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from pplm_classification_head import ClassificationHead\n",
    "from torch import nn\n",
    "from tqdm import trange\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,BertTokenizerFast, BertModel\n",
    "#from transformers.file_utils import cached_path\n",
    "from cached_path import cached_path\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        #참고로 'bert-base-uncased' 모델은 버트의 가장 기본적인 모델을 의미\n",
    "        #uncased는 모든 문장을 소문자로 대체하겠다는 것 \n",
    "        \n",
    "        self.classifier  = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768,2)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        \n",
    "        #print(inputs['input_ids'].shape)  \n",
    "        bert_outputs = self.bert(**inputs,return_dict =True)\n",
    "        #print(\"bert_outputs\",bert_outputs)\n",
    "        pooler_output = bert_outputs.last_hidden_state[:,0]\n",
    "        # bert_outputs.last_hidden_state[:,0] -> 첫번째니까 [cls] 토큰의\n",
    "        # embedding만을 뽑아내어 classification task를 위한 텐서로 변환한다? \n",
    "        #print(\"pooler_output\",pooler_output.shape)\n",
    "        \n",
    "        logits = self.classifier(pooler_output)\n",
    "        #print(\"logits\",logits.shape)\n",
    "        \n",
    "        return logits\n",
    "PPLM_BOW = 1\n",
    "PPLM_DISCRIM = 2\n",
    "PPLM_BOW_DISCRIM = 3\n",
    "SMALL_CONST = 1e-15\n",
    "BIG_CONST = 1e10\n",
    "\n",
    "BAG_OF_WORDS_ARCHIVE_MAP = {\n",
    "    \"legal\": \"https://s3.amazonaws.com/models.huggingface.co/bert/pplm/bow/legal.txt\",\n",
    "    \"military\": \"https://s3.amazonaws.com/models.huggingface.co/bert/pplm/bow/military.txt\",\n",
    "    \"politics\": \"https://s3.amazonaws.com/models.huggingface.co/bert/pplm/bow/politics.txt\",\n",
    "    \"religion\": \"https://s3.amazonaws.com/models.huggingface.co/bert/pplm/bow/religion.txt\",\n",
    "    \"science\": \"https://s3.amazonaws.com/models.huggingface.co/bert/pplm/bow/science.txt\",\n",
    "    \"space\": \"https://s3.amazonaws.com/models.huggingface.co/bert/pplm/bow/space.txt\",\n",
    "    \"technology\": \"https://s3.amazonaws.com/models.huggingface.co/bert/pplm/bow/technology.txt\",\n",
    "}\n",
    "\n",
    "DISCRIMINATOR_MODELS_PARAMS = {\n",
    "    \"clickbait\": {\n",
    "        \"url\": \"https://s3.amazonaws.com/models.huggingface.co/bert/pplm/discriminators/clickbait_classifier_head.pt\",\n",
    "        \"class_size\": 2,\n",
    "        \"embed_size\": 1024,\n",
    "        \"class_vocab\": {\"non_clickbait\": 0, \"clickbait\": 1},\n",
    "        \"default_class\": 1,\n",
    "        \"pretrained_model\": \"llama\",\n",
    "    },\n",
    "    \"sentiment\": {\n",
    "        #\"url\": \"https://s3.amazonaws.com/models.huggingface.co/bert/pplm/discriminators/SST_classifier_head.pt\",\n",
    "        \"url\": \"SST_classifier_head_epoch_9.pt\",\n",
    "        \"class_size\": 5,\n",
    "        \"embed_size\": 4096,\n",
    "        \"class_vocab\": {\"very_positive\": 2, \"very_negative\": 3},\n",
    "        \"default_class\": 3,\n",
    "        \"pretrained_model\": \"llama\",\n",
    "    },\n",
    "}\n",
    "\n",
    "def ngrams(sequence, n, pad_left=False, pad_right=False,\n",
    "           left_pad_symbol=None, right_pad_symbol=None):\n",
    "    sequence = pad_sequence(sequence, n, pad_left, pad_right,\n",
    "                            left_pad_symbol, right_pad_symbol)\n",
    "\n",
    "    history = []\n",
    "    while n > 1:\n",
    "        history.append(next(sequence))\n",
    "        n -= 1\n",
    "    for item in sequence:\n",
    "        history.append(item)\n",
    "        yield tuple(history)\n",
    "        del history[0]\n",
    "def pad_sequence(sequence, n, pad_left=False, pad_right=False,\n",
    "                 left_pad_symbol=None, right_pad_symbol=None):\n",
    "\n",
    "    sequence = iter(sequence)\n",
    "    if pad_left:\n",
    "        sequence = chain((left_pad_symbol,) * (n - 1), sequence)\n",
    "    if pad_right:\n",
    "        sequence = chain(sequence, (right_pad_symbol,) * (n - 1))\n",
    "    return sequence\n",
    "def distinct_n_sentence_level(sentence, n):\n",
    "    if len(sentence) == 0:\n",
    "        return 0.0  # Prevent a zero division\n",
    "    distinct_ngrams = set(ngrams(sentence, n))\n",
    "    return len(distinct_ngrams) / len(sentence)\n",
    "def distinct_n_corpus_level(sentences, n):\n",
    "   \n",
    "    return sum(distinct_n_sentence_level(sentence, n) for sentence in sentences) / len(sentences)\n",
    "def top_k_filter(logits, k, probs=False):\n",
    "    \"\"\"\n",
    "    Masks everything but the k top entries as -infinity (1e10).\n",
    "    Used to mask logits such that e^-infinity -> 0 won't contribute to the\n",
    "    sum of the denominator.\n",
    "    \"\"\"\n",
    "    if k == 0:\n",
    "        return logits\n",
    "    else:\n",
    "        values = torch.topk(logits, k)[0]\n",
    "        batch_mins = values[:, -1].view(-1, 1).expand_as(logits)\n",
    "        if probs:\n",
    "            return torch.where(logits < batch_mins, torch.ones_like(logits) * 0.0, logits)\n",
    "        return torch.where(logits < batch_mins, torch.ones_like(logits) * -BIG_CONST, logits)\n",
    "def get_classifier(\n",
    "    name: Optional[str], class_label: Union[str, int], device: str\n",
    ") -> Tuple[Optional[ClassificationHead], Optional[int]]:\n",
    "    if name is None:\n",
    "        return None, None\n",
    "\n",
    "    params = DISCRIMINATOR_MODELS_PARAMS[name]\n",
    "    classifier = ClassificationHead(class_size=params[\"class_size\"], embed_size=params[\"embed_size\"]).to(device)\n",
    "    if \"url\" in params:\n",
    "        resolved_archive_file = cached_path(params[\"url\"])\n",
    "    elif \"path\" in params:\n",
    "        resolved_archive_file = params[\"path\"]\n",
    "    else:\n",
    "        raise ValueError(\"Either url or path have to be specified in the discriminator model parameters\")\n",
    "    classifier.load_state_dict(torch.load(resolved_archive_file, map_location=device))\n",
    "    classifier.eval()\n",
    "\n",
    "    if isinstance(class_label, str):\n",
    "        if class_label in params[\"class_vocab\"]:\n",
    "            label_id = params[\"class_vocab\"][class_label]\n",
    "        else:\n",
    "            label_id = params[\"default_class\"]\n",
    "            print(\"class_label {} not in class_vocab\".format(class_label))\n",
    "            print(\"available values are: {}\".format(params[\"class_vocab\"]))\n",
    "            print(\"using default class {}\".format(label_id))\n",
    "\n",
    "    elif isinstance(class_label, int):\n",
    "        if class_label in set(params[\"class_vocab\"].values()):\n",
    "            label_id = class_label\n",
    "        else:\n",
    "            label_id = params[\"default_class\"]\n",
    "            print(\"class_label {} not in class_vocab\".format(class_label))\n",
    "            print(\"available values are: {}\".format(params[\"class_vocab\"]))\n",
    "            print(\"using default class {}\".format(label_id))\n",
    "\n",
    "    else:\n",
    "        label_id = params[\"default_class\"]\n",
    "\n",
    "    return classifier, label_id\n",
    "\n",
    "\n",
    "def get_bag_of_words_indices(bag_of_words_ids_or_paths: List[str], tokenizer) -> List[List[List[int]]]:\n",
    "    bow_indices = []\n",
    "    for id_or_path in bag_of_words_ids_or_paths:\n",
    "        if id_or_path in BAG_OF_WORDS_ARCHIVE_MAP:\n",
    "            filepath = cached_path(BAG_OF_WORDS_ARCHIVE_MAP[id_or_path])\n",
    "        else:\n",
    "            filepath = id_or_path\n",
    "        with open(filepath, \"r\") as f:\n",
    "            words = f.read().strip().split(\"\\n\")\n",
    "        bow_indices.append([tokenizer.encode(word.strip(), add_prefix_space=True) for word in words])\n",
    "    return bow_indices\n",
    "\n",
    "\n",
    "def build_bows_one_hot_vectors(bow_indices, tokenizer, device=\"cuda\"):\n",
    "    if bow_indices is None:\n",
    "        return None\n",
    "\n",
    "    one_hot_bows_vectors = []\n",
    "    for single_bow in bow_indices:\n",
    "        single_bow = list(filter(lambda x: len(x) <= 1, single_bow))\n",
    "        single_bow = torch.tensor(single_bow).to(device)\n",
    "        num_words = single_bow.shape[0]\n",
    "        one_hot_bow = torch.zeros(num_words, tokenizer.vocab_size).to(device)\n",
    "        one_hot_bow.scatter_(1, single_bow, 1)\n",
    "        one_hot_bows_vectors.append(one_hot_bow)\n",
    "    return one_hot_bows_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebc2f988-9d28-410d-b557-2e37ad735f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed= 0 \n",
    "no_cuda = False\n",
    "discrim = 'sentiment'\n",
    "uncond = False\n",
    "cond_text = 'I am studying'\n",
    "num_samples = 2\n",
    "bag_of_words = None\n",
    "class_label = 2\n",
    "length = 5\n",
    "stepsize = 0.04\n",
    "temperature = 1.0\n",
    "top_k = 10\n",
    "sample = True\n",
    "num_iterations= 1\n",
    "grad_length = 10000\n",
    "horizon_length = 1\n",
    "window_length = 0\n",
    "decay = False\n",
    "gamma = 1.0\n",
    "gm_scale = 0.95\n",
    "kl_scale = 0.01\n",
    "repetition_penalty = 1.0\n",
    "perturb_layer = 100\n",
    "bow_indices = None\n",
    "one_hot_bows_vectors = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6632c80-9a3b-4356-a621-9df99062218d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "617.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(781+774+548+365)/4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c193e26c-221e-4601-8ac1-19683fb8d585",
   "metadata": {},
   "source": [
    "# 1. run_pplm_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1882819-6859-47b3-a041-cf00f32cee71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discrim = sentiment, pretrained_model set to discriminator's = llama\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecf5f44714f411a99970227349ce91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\"\n",
    "\n",
    "pretrained_model = DISCRIMINATOR_MODELS_PARAMS[discrim][\"pretrained_model\"]\n",
    "print(\"discrim = {}, pretrained_model set to discriminator's = {}\".format(discrim, pretrained_model))\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/home/wooseok/llama-7b-hf\",\n",
    "                                             device_map=\"auto\",\n",
    "                                             load_in_8bit=True)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad7aada6-3637-45c9-bac6-83d0905d1e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= Prefix of sentence =\n",
      "<s> The movie was\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/wooseok/llama-7b-hf\",\n",
    "                                          unk_token=\"<unk>\",\n",
    "                                                    bos_token=\"<s>\",\n",
    "                                                    #eos_token=\"</s>\"\n",
    "                                         )\n",
    "# Freeze llama weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# figure out conditioning text\n",
    "cond_text = \"The movie was\"\n",
    "raw_text = cond_text\n",
    "tokenized_cond_text = tokenizer.encode(raw_text)\n",
    "\n",
    "context = tokenized_cond_text\n",
    "\n",
    "print(\"= Prefix of sentence =\")\n",
    "print(tokenizer.decode(tokenized_cond_text))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b660d-91c2-4f28-9617-523dd5eb56ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df028171-1e59-4628-8cee-ab937b004a77",
   "metadata": {},
   "source": [
    "# 2.Full_text_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a8abc4b-7e69-4f27-aa66-72bb852c6ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationHead(\n",
      "  (mlp): Linear(in_features=4096, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "classifier, class_id = get_classifier(discrim, class_label, device)\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2a5a3bc-9538-4f8f-bff3-2b3971e8253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type = PPLM_DISCRIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b87376-12ae-43f4-833c-454fd6f84d7d",
   "metadata": {},
   "source": [
    "## 2.1 섭동 안줄 때 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e2b78a5-2ab8-4f95-8cc1-6be70836534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_pplm(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    context=None,\n",
    "    past=None,\n",
    "    device=\"cuda\",\n",
    "    perturb=True,\n",
    "    bow_indices=None,\n",
    "    classifier=None,\n",
    "    class_label=None,\n",
    "    loss_type=0,\n",
    "    length=100,\n",
    "    stepsize=0.02,\n",
    "    temperature=1.0,\n",
    "    top_k=10,\n",
    "    sample=False,\n",
    "    num_iterations=3,\n",
    "    grad_length=10000,\n",
    "    horizon_length=1,\n",
    "    window_length=0,\n",
    "    decay=False,\n",
    "    gamma=1.5,\n",
    "    gm_scale=0.9,\n",
    "    kl_scale=0.01,\n",
    "    repetition_penalty=1.0,\n",
    "    perturb_layer = 100,\n",
    "):\n",
    "    output_so_far = None\n",
    "    if context:\n",
    "        context_t = torch.tensor(context, device=device, dtype=torch.long)\n",
    "        while len(context_t.shape) < 2:\n",
    "            context_t = context_t.unsqueeze(0)\n",
    "        output_so_far = context_t # tensor([[    1,   306,   626, 23382]], device='cuda:0')\n",
    "        \n",
    "    grad_norms = None\n",
    "    last = None\n",
    "    unpert_discrim_loss = 0\n",
    "    loss_in_time = []\n",
    "    for i in trange(length, ascii=True):\n",
    "        # Get past/probs for current output, except for last word\n",
    "        # Note that GPT takes 2 inputs: past + current_token\n",
    "\n",
    "        # run model forward to obtain unperturbed\n",
    "        if past is None and output_so_far is not None:\n",
    "            last = output_so_far[:, -1:]\n",
    "            if output_so_far.shape[1] > 1:\n",
    "            \n",
    "                \n",
    "                past = model(output_so_far[:, :-1],return_dict =True)[\"past_key_values\"]\n",
    "                #print(len(past))\n",
    "                #print(len(past[0]))\n",
    "                #print(past[0][0].sha)\n",
    "\n",
    "        lm_output = model(output_so_far,return_dict =True,output_hidden_states=True)\n",
    "        unpert_logits, unpert_past, unpert_all_hidden = (\n",
    "            lm_output[\"logits\"],\n",
    "            lm_output[\"past_key_values\"],\n",
    "            lm_output[\"hidden_states\"],\n",
    "        )\n",
    "        unpert_last_hidden = unpert_all_hidden[-1]\n",
    "\n",
    "        # check if we are abowe grad max length\n",
    "        if i >= grad_length:\n",
    "            current_stepsize = stepsize * 0\n",
    "        else:\n",
    "            current_stepsize = stepsize\n",
    "\n",
    "        # modify the past if necessary\n",
    "        if not perturb or num_iterations == 0:\n",
    "            pert_past = past\n",
    "        else:\n",
    "            accumulated_hidden = unpert_last_hidden[:, :-1, :]\n",
    "            accumulated_hidden = torch.sum(accumulated_hidden, dim=1)\n",
    "\n",
    "            if past is not None:\n",
    "                pert_past, _, grad_norms, loss_this_iter = perturb_past(\n",
    "                    past,\n",
    "                    model,\n",
    "                    last,\n",
    "                    unpert_past=unpert_past,\n",
    "                    unpert_logits=unpert_logits,\n",
    "                    accumulated_hidden=accumulated_hidden,\n",
    "                    grad_norms=grad_norms,\n",
    "                    stepsize=current_stepsize,\n",
    "                    one_hot_bows_vectors=one_hot_bows_vectors,\n",
    "                    classifier=classifier,\n",
    "                    class_label=class_label,\n",
    "                    loss_type=loss_type,\n",
    "                    num_iterations=num_iterations,\n",
    "                    horizon_length=horizon_length,\n",
    "                    window_length=window_length,\n",
    "                    decay=decay,\n",
    "                    gamma=gamma,\n",
    "                    kl_scale=kl_scale,\n",
    "                    perturb_layer = perturb_layer,\n",
    "                    device=device,\n",
    "                )\n",
    "                loss_in_time.append(loss_this_iter)\n",
    "            else:\n",
    "                pert_past = past\n",
    "        ######## past type 맞춰주기\n",
    "        qqqq= []\n",
    "        for i in range(len(pert_past)):\n",
    "            qqqq.append(torch.stack([pert_past[i][0],pert_past[i][1]]))\n",
    "        pert_past = qqqq\n",
    "        for i in range(len(pert_past)):\n",
    "            pert_past[i] = pert_past[i].to(torch.float16)\n",
    "        ######## past type 맞춰주기 끝 \n",
    "        \n",
    "        lm_output = model(last, past_key_values=pert_past,return_dict =True,output_hidden_states=True)\n",
    "        pert_logits, past = (\n",
    "            lm_output[\"logits\"],\n",
    "            lm_output[\"past_key_values\"],\n",
    "        )\n",
    "        \n",
    "        pert_logits = pert_logits[:, -1, :] / temperature  # + SMALL_CONST\n",
    "\n",
    "        for token_idx in set(output_so_far[0].tolist()):\n",
    "            if pert_logits[0, token_idx] < 0:\n",
    "                pert_logits[0, token_idx] *= repetition_penalty\n",
    "            else:\n",
    "                pert_logits[0, token_idx] /= repetition_penalty\n",
    "\n",
    "        pert_probs = nn.functional.softmax(pert_logits, dim=-1)\n",
    "\n",
    "        if classifier is not None:\n",
    "            ce_loss = nn.CrossEntropyLoss()\n",
    "            prediction = classifier(torch.mean(unpert_last_hidden, dim=1))\n",
    "            label = torch.tensor([class_label], device=device, dtype=torch.long)\n",
    "            unpert_discrim_loss = ce_loss(prediction, label)\n",
    "            print(\"unperturbed discrim loss\", unpert_discrim_loss.data.cpu().numpy())\n",
    "        else:\n",
    "            unpert_discrim_loss = 0\n",
    "\n",
    "        # Fuse the modified model and original model\n",
    "        if perturb:\n",
    "            unpert_probs = nn.functional.softmax(unpert_logits[:, -1, :], dim=-1)\n",
    "\n",
    "            pert_probs = (pert_probs**gm_scale) * (unpert_probs ** (1 - gm_scale))  # + SMALL_CONST\n",
    "            pert_probs = top_k_filter(pert_probs, k=top_k, probs=True)  # + SMALL_CONST\n",
    "\n",
    "            # rescale\n",
    "            if torch.sum(pert_probs) <= 1:\n",
    "                pert_probs = pert_probs / torch.sum(pert_probs)\n",
    "\n",
    "        else:\n",
    "            pert_logits = top_k_filter(pert_logits, k=top_k)  # + SMALL_CONST\n",
    "            pert_probs = nn.functional.softmax(pert_logits, dim=-1)\n",
    "\n",
    "        # sample or greedy\n",
    "        if sample:\n",
    "            last = torch.multinomial(pert_probs, num_samples=1)\n",
    "\n",
    "        else:\n",
    "            _, last = torch.topk(pert_probs, k=1, dim=-1)\n",
    "\n",
    "        # update context/output_so_far appending the new token\n",
    "        output_so_far = last if output_so_far is None else torch.cat((output_so_far, last), dim=1)\n",
    "\n",
    "        print(tokenizer.decode(output_so_far.tolist()[0]))\n",
    "\n",
    "    return output_so_far, unpert_discrim_loss, loss_in_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa773d6-abe3-45a9-81d7-ac92f0626ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|#################                                                                    | 1/5 [00:04<00:16,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> The movie was directed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|##################################                                                   | 2/5 [00:05<00:06,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> The movie was directed by\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|###################################################                                  | 3/5 [00:07<00:04,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> The movie was directed by Raj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|####################################################################                 | 4/5 [00:09<00:02,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> The movie was directed by Rajk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################################################| 5/5 [00:10<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> The movie was directed by Rajkumar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unpert_gen_tok_text, _, _ = generate_text_pplm(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        context=context,\n",
    "        device=device,\n",
    "        length=length,\n",
    "        sample=sample,\n",
    "        perturb=False,\n",
    "        repetition_penalty=repetition_penalty,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28104120-e946-4538-9b2e-f4f234ec4d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 450, 14064, 471]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4217c1d-60e5-45a2-9569-b07be614a241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   450, 14064,   471]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_text = 'The movie was'\n",
    "\n",
    "raw_text = cond_text\n",
    "tokenized_cond_text = tokenizer.encode(raw_text)\n",
    "\n",
    "context = tokenized_cond_text\n",
    "\n",
    "output_so_far = None\n",
    "past = None\n",
    "perturb=False\n",
    "if context:\n",
    "    context_t = torch.tensor(context, device=device, dtype=torch.long)\n",
    "    while len(context_t.shape) < 2:\n",
    "        context_t = context_t.unsqueeze(0)\n",
    "    output_so_far = context_t # tensor([[    1,   306,   626, 23382]], device='cuda:0')\n",
    "output_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68cc4929-088a-4f13-97a5-8e69eabce2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   450, 14064,   471]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37348544-f127-4f91-87ea-7c4126039230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['logits', 'past_key_values', 'hidden_states'])\n"
     ]
    }
   ],
   "source": [
    "lm_output= model(output_so_far\n",
    "                 ,return_dict=True,output_hidden_states=True)\n",
    "\n",
    "print(lm_output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23c56b12-5852-457a-bf2e-e6c0b7591934",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_output= model(output_so_far\n",
    "                 ,return_dict=True,output_hidden_states=True)\n",
    "\n",
    "logit = lm_output[\"logits\"] \n",
    "# torch.Size([1, 4, 32000])\n",
    "# batch_size, sequence_length, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce1b5103-58f7-410e-9440-acbd17b56da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,   450, 14064,   471,  5492]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "probs = nn.functional.softmax(logit[:,-1,:], dim=-1)\n",
    "last = torch.topk(probs, k=1, dim=-1)[1]\n",
    "output_so_far =torch.cat((output_so_far, last), dim=1)\n",
    "print(output_so_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b02c460a-3e7d-4062-b184-3db3a34348bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_output= model(output_so_far\n",
    "                 ,return_dict=True,output_hidden_states=True)\n",
    "\n",
    "past = lm_output[\"past_key_values\"]\n",
    "# 32, 2, torch.Size([1, 32,4, 128])\n",
    "# layer 수, key_value 2개,(batch_size, num_heads, sequence_length, embed_size_per_head)\n",
    "\n",
    "hidden_states = lm_output[\"hidden_states\"]\n",
    "# 33, torch.Size([1, 4, 4096])\n",
    "# layer수+1, (batch_size, sequence_length, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b924b5c9-ecd1-492f-9d0c-26f22d7906bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_output= model(output_so_far\n",
    "                 ,return_dict=True,output_hidden_states=True)\n",
    "\n",
    "hidden_states = lm_output[\"hidden_states\"]\n",
    "# 33, torch.Size([1, 4, 4096])\n",
    "# layer수+1, (batch_size, sequence_length, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7567f52-30fa-4e0e-9e15-e4394e4d45f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 32000])\n",
      "32 2 torch.Size([1, 32, 5, 128])\n",
      "33 torch.Size([1, 5, 4096])\n",
      "tensor([[    1,   450, 14064,   471,  5492,   297]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "lm_output= model(output_so_far\n",
    "                 ,return_dict=True,output_hidden_states=True)\n",
    "\n",
    "logit, past, hidden_states= (\n",
    "    lm_output[\"logits\"], \n",
    "    # torch.Size([1, 4, 32000])\n",
    "    # batch_size, sequence_length, vocab_size\n",
    "    \n",
    "    lm_output[\"past_key_values\"],\n",
    "    # 32, 2, torch.Size([1, 32,4, 128])\n",
    "    # layer 수, key_value 2개,(batch_size, num_heads, sequence_length, embed_size_per_head)\n",
    "    \n",
    "    lm_output[\"hidden_states\"])\n",
    "    # 33, torch.Size([1, 4, 4096])\n",
    "    # layer수+1, (batch_size, sequence_length, hidden_size)\n",
    "\n",
    "print(logit.shape)\n",
    "print(len(past),len(past[0]),past[0][0].shape)    \n",
    "print(len(hidden_states),hidden_states[0].shape)    \n",
    "    \n",
    "probs = nn.functional.softmax(logit[:,-1,:], dim=-1)\n",
    "last = torch.topk(probs, k=1, dim=-1)[1]\n",
    "output_so_far =torch.cat((output_so_far, last), dim=1)\n",
    "print(output_so_far)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4da3ae28-c9dd-4bed-b931-5d36a75d3e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> The movie was released in\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output_so_far.tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ce33b10-a32a-4761-a130-ab7426307ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> The movie was released in in\n"
     ]
    }
   ],
   "source": [
    "probs = nn.functional.softmax(logit[:,-1,:], dim=-1)\n",
    "last = torch.topk(probs, k=1, dim=-1)[1]\n",
    "output_so_far =torch.cat((output_so_far, last), dim=1)\n",
    "print(tokenizer.decode(output_so_far.tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf0e4a49-636e-42ee-9c58-be3807a03538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,     1,   450, 14064,   471]], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_text = 'The movie was'\n",
    "\n",
    "raw_text = cond_text\n",
    "tokenized_cond_text = tokenizer.encode(tokenizer.bos_token + raw_text)\n",
    "\n",
    "context = tokenized_cond_text\n",
    "\n",
    "output_so_far = None\n",
    "past = None\n",
    "perturb=False\n",
    "if context:\n",
    "    context_t = torch.tensor(context, device=device, dtype=torch.long)\n",
    "    while len(context_t.shape) < 2:\n",
    "        context_t = context_t.unsqueeze(0)\n",
    "    output_so_far = context_t # tensor([[    1,   306,   626, 23382]], device='cuda:0')\n",
    "output_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9d4d537-1475-4ad6-a4d4-1493b60b1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "last = output_so_far[:, -1:] # 마지막 단어\n",
    "past = model(output_so_far[:, :-1],return_dict =True)[\"past_key_values\"] #이전단어들의 key_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f2750da-3869-48ba-b6e6-5d69505b3314",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_output= model(last, past_key_values=past,\n",
    "                 return_dict=True,output_hidden_states=True)  \n",
    "logit, past = (\n",
    "    lm_output[\"logits\"], \n",
    "    # torch.Size([1, 1, 32000]\n",
    "    \n",
    "    lm_output[\"past_key_values\"]) \n",
    "    # 32, 2, torch.Size([1, 32, Sequence_len, 128]) )\n",
    "probs = nn.functional.softmax(logit[:,-1,:], dim=-1)\n",
    "last = torch.topk(probs, k=1, dim=-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d46e6e74-bf04-4ec7-842f-63a922f7d4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32000])\n",
      "32 2 torch.Size([1, 32, 5, 128])\n"
     ]
    }
   ],
   "source": [
    "print(logit.shape)\n",
    "print(len(past),len(past[0]),past[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e6ad44b-6124-4b83-a907-a56484ac2b2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perturb_past' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pert_past \u001b[38;5;241m=\u001b[39m \u001b[43mperturb_past\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'perturb_past' is not defined"
     ]
    }
   ],
   "source": [
    "pert_past = perturb_past()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a382cc5e-eebd-401f-a2d7-e5d95fffa6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 단어와,past를 input으로 넣음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5adec9f9-87ad-4d55-9b0c-c78b00021faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = nn.functional.softmax(logit[:,-1,:], dim=-1)\n",
    "last = torch.topk(probs, k=1, dim=-1)[1]\n",
    "\n",
    "output_so_far =torch.cat((output_so_far, last), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcf03606-3233-4b97-a35f-7fb51787223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_so_far =torch.cat((output_so_far, last), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed16881e-f35b-43e1-a73f-4b601d5e4806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_so_far.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73e0fa0f-d149-45f8-aa4e-524863736d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32000])\n",
      "32 2 torch.Size([1, 32, 5, 128])\n"
     ]
    }
   ],
   "source": [
    "print(logit.shape)\n",
    "print(len(past),len(past[0]),past[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6510437b-9f18-401c-9e57-6b5fa326b31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><s> The movie was released released\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output_so_far.tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ab98c27-92b2-4436-9d12-883634beb35f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,     1,   450, 14064,   471,  5492,  5492]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a087e064-9a2a-475d-adef-c2ba3d8813a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 torch.Size([1, 5, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(len(hidden_states),hidden_states[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f785964-ff71-49a0-9008-792059ef4a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 4096])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1924f05e-4276-4a89-9ef3-933c5c00b621",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a_probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma_probs\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a_probs' is not defined"
     ]
    }
   ],
   "source": [
    "a_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01f409eb-e9b1-4501-aa1b-513ed1e4ae22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95731bf5-0bdc-4022-82ff-19c905f3f8de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f93a5f6b-1110-40b4-a8fc-3d72a6553935",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_past[0][0] == b_past[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5021da76-2543-480a-99f9-b0f55f3024a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   306,   626, 23382]], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_so_far[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c9f510e-461e-40c3-b35a-865dd725f100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([4, 32000]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model(output_so_far[:, :-1],return_dict =True)['logits']),model(output_so_far[:, :-1],return_dict =True)['logits'][0].shape\n",
    "#(batch_size, sequence_length, config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "20fa9cb8-fc22-4c54-9005-a06896673ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   306,   626, 23382,  4223,  5449,  1535,  1363,   372]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8a4296f8-68e2-4002-8b88-cb1eb1138ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values'])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(output_so_far).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "11afe5d3-ac5c-4324-b7e1-f8b958c23db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values', 'hidden_states'])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(output_so_far,return_dict =True,output_hidden_states=True).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31c2b430-0334-4c83-8ad9-734bf4e7d274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values', 'hidden_states'])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(last, past_key_values=pert_past,return_dict =True,output_hidden_states=True).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f893049e-f577-4457-a346-4fc1f58505f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[372]], device='cuda:0')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e8602957-0cb6-4d07-99e4-19957368c5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 306, 626, 23382]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6762896-2f5a-4b58-8699-2ada41f0b7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                             | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 torch.Size([1, 5, 4096])\n",
      "tensor([[23382]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|#################                                                                    | 1/5 [00:03<00:14,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unperturbed discrim loss 5.120018\n",
      "torch.Size([1, 32000]) zzz\n",
      "<s><s> I am studying how\n",
      "33 torch.Size([1, 6, 4096])\n",
      "tensor([[920]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|##################################                                                   | 2/5 [00:05<00:08,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unperturbed discrim loss 4.457481\n",
      "torch.Size([1, 32000]) zzz\n",
      "<s><s> I am studying how the\n",
      "33 torch.Size([1, 7, 4096])\n",
      "tensor([[278]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|###################################################                                  | 3/5 [00:07<00:04,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unperturbed discrim loss 3.8468409\n",
      "torch.Size([1, 32000]) zzz\n",
      "<s><s> I am studying how the different\n",
      "33 torch.Size([1, 8, 4096])\n",
      "tensor([[1422]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|####################################################################                 | 4/5 [00:08<00:01,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unperturbed discrim loss 3.5742111\n",
      "torch.Size([1, 32000]) zzz\n",
      "<s><s> I am studying how the different parts\n",
      "33 torch.Size([1, 9, 4096])\n",
      "tensor([[5633]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################################################| 5/5 [00:09<00:00,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unperturbed discrim loss 3.708449\n",
      "torch.Size([1, 32000]) zzz\n",
      "<s><s> I am studying how the different parts of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cond_text = 'I am studying'\n",
    "\n",
    "raw_text = cond_text\n",
    "tokenized_cond_text = tokenizer.encode(tokenizer.bos_token + raw_text)\n",
    "\n",
    "context = tokenized_cond_text\n",
    "\n",
    "output_so_far = None\n",
    "past = None\n",
    "perturb=False\n",
    "if context:\n",
    "    context_t = torch.tensor(context, device=device, dtype=torch.long)\n",
    "    while len(context_t.shape) < 2:\n",
    "        context_t = context_t.unsqueeze(0)\n",
    "    output_so_far = context_t # tensor([[    1,   306,   626, 23382]], device='cuda:0')\n",
    "\n",
    "grad_norms = None\n",
    "last = None\n",
    "unpert_discrim_loss = 0\n",
    "loss_in_time = []\n",
    "for i in trange(length, ascii=True):\n",
    "    \n",
    "    # Get past/probs for current output, except for last word\n",
    "    # Note that GPT takes 2 inputs: past + current_token\n",
    "\n",
    "    # run model forward to obtain unperturbed\n",
    "    if past is None and output_so_far is not None: # 제일 처음에만 얘한테 걸림. \n",
    "        \n",
    "        last = output_so_far[:, -1:] # 마지막 단어\n",
    "        if output_so_far.shape[1] > 1:\n",
    "            past = model(output_so_far[:, :-1],return_dict =True)[\"past_key_values\"] # 이전 단어들을 input으로 넣어서 첫 past 만듬. \n",
    "            #print(len(past),len(past[0]),past[0][0].shape) #layer수,keyvalue, torch.Size([1, 32, 3, 128]) (batch_size, num_heads, sequence_length, embed_size_per_head)\n",
    "\n",
    "    lm_output = model(output_so_far,return_dict =True,output_hidden_states=True)\n",
    "    unpert_logits, unpert_past, unpert_all_hidden = (\n",
    "        lm_output[\"logits\"], #Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax). #(batch_size, sequence_length, vocab_size)\n",
    "        lm_output[\"past_key_values\"], # #layer수,keyvalue, (batch_size, num_heads, sequence_length, embed_size_per_head(key 벡터의 길이))\n",
    "        lm_output[\"hidden_states\"], #layer 수, (batch_size, sequence_length, hidden_size(sequence를 이 벡터 길이만큼 표현하겠다)).\n",
    "    )\n",
    "    #print(unpert_logits.shape) #(batch_size, sequence_length, config.vocab_size)\n",
    "    #print(len(unpert_past),len(unpert_past[0]),unpert_past[0][0].shape)\n",
    "    print(len(unpert_all_hidden),unpert_all_hidden[0].shape) #33 torch.Size([1, 4, 4096])\n",
    "    unpert_last_hidden = unpert_all_hidden[-1]\n",
    "    #print(unpert_last_hidden.shape)\n",
    "   \n",
    "    current_stepsize = stepsize\n",
    "\n",
    "    # modify the past if necessary\n",
    "    if not perturb or num_iterations == 0:\n",
    "        pert_past = past\n",
    "    '''\n",
    "    ####################################### perturb 하는 부분 #################################\n",
    "    else:\n",
    "            accumulated_hidden = unpert_last_hidden[:, :-1, :]\n",
    "            accumulated_hidden = torch.sum(accumulated_hidden, dim=1)\n",
    "\n",
    "            if past is not None:\n",
    "                pert_past, _, grad_norms, loss_this_iter = perturb_past(\n",
    "                    past,\n",
    "                    model,\n",
    "                    last,\n",
    "                    unpert_past=unpert_past,\n",
    "                    unpert_logits=unpert_logits,\n",
    "                    accumulated_hidden=accumulated_hidden,\n",
    "                    grad_norms=grad_norms,\n",
    "                    stepsize=current_stepsize,\n",
    "                    one_hot_bows_vectors=one_hot_bows_vectors,\n",
    "                    classifier=classifier,\n",
    "                    class_label=class_label,\n",
    "                    loss_type=loss_type,\n",
    "                    num_iterations=num_iterations,\n",
    "                    horizon_length=horizon_length,\n",
    "                    window_length=window_length,\n",
    "                    decay=decay,\n",
    "                    gamma=gamma,\n",
    "                    kl_scale=kl_scale,\n",
    "                    perturb_layer = perturb_layer,\n",
    "                    device=device,\n",
    "                )\n",
    "                loss_in_time.append(loss_this_iter)\n",
    "            else:\n",
    "                pert_past = past         \n",
    "    ####################################### perturb 하는 부분 끝 #################################\n",
    "    '''\n",
    "    ''' past type 맞춰주기'''\n",
    "    qqqq= []\n",
    "    for i in range(len(pert_past)):\n",
    "        qqqq.append(torch.stack([pert_past[i][0],pert_past[i][1]]))\n",
    "    pert_past = qqqq\n",
    "    for i in range(len(pert_past)):\n",
    "        pert_past[i] = pert_past[i].to(torch.float16)\n",
    "    '''past type 맞춰주기 끝''' \n",
    "    \n",
    "    print(last)\n",
    "    lm_output = model(last, past_key_values=pert_past,return_dict =True,output_hidden_states=True) # 마지막 단어와,past를 input으로 넣음. \n",
    "    pert_logits, past = (\n",
    "        lm_output[\"logits\"], # torch.Size([1, 1, 32000])\n",
    "        lm_output[\"past_key_values\"],\n",
    "    )\n",
    "    #print(pert_logits.shape) #(batch_size, sequence_length=1, config.vocab_size)\n",
    "    #print(len(past),len(past[0]),past[0][0].shape)\n",
    "    \n",
    "    ''' temperatute_scailing, repetition_penalty으로 pert_logits 건드리기'''\n",
    "    pert_logits = pert_logits[:, -1, :] / temperature  # + SMALL_CONST\n",
    "    #print(pert_logits.shape) # torch.Size([1, 32000])\n",
    "    #print(output_so_far[0])\n",
    "    for token_idx in set(output_so_far[0].tolist()):\n",
    "        if pert_logits[0, token_idx] < 0:\n",
    "            pert_logits[0, token_idx] *= repetition_penalty\n",
    "        else:\n",
    "            pert_logits[0, token_idx] /= repetition_penalty\n",
    "    ''' temperatute_scailing, repetition_penalty 끝'''\n",
    "    \n",
    "    pert_probs = nn.functional.softmax(pert_logits, dim=-1)\n",
    "    \n",
    "    if classifier is not None:\n",
    "        ce_loss = nn.CrossEntropyLoss()\n",
    "        prediction = classifier(torch.mean(unpert_last_hidden, dim=1))\n",
    "        label = torch.tensor([class_label], device=device, dtype=torch.long)\n",
    "        unpert_discrim_loss = ce_loss(prediction, label)\n",
    "        print(\"unperturbed discrim loss\", unpert_discrim_loss.data.cpu().numpy())\n",
    "    else:\n",
    "        unpert_discrim_loss = 0\n",
    "\n",
    "    # Fuse the modified model and original model\n",
    "    if perturb: \n",
    "        unpert_probs = nn.functional.softmax(unpert_logits[:, -1, :], dim=-1)\n",
    "\n",
    "        pert_probs = (pert_probs**gm_scale) * (unpert_probs ** (1 - gm_scale))  # + SMALL_CONST\n",
    "        pert_probs = top_k_filter(pert_probs, k=top_k, probs=True)  # + SMALL_CONST\n",
    "\n",
    "        # rescale\n",
    "        if torch.sum(pert_probs) <= 1:\n",
    "            pert_probs = pert_probs / torch.sum(pert_probs)\n",
    "    else:\n",
    "        pert_logits = top_k_filter(pert_logits, k=top_k)  # + SMALL_CONST\n",
    "        print(pert_logits.shape,\"zzz\")\n",
    "        pert_probs = nn.functional.softmax(pert_logits, dim=-1)\n",
    "        \n",
    "    # sample or greedy\n",
    "    if sample:\n",
    "        last = torch.multinomial(pert_probs, num_samples=1)\n",
    "\n",
    "    else:\n",
    "        _, last = torch.topk(pert_probs, k=1, dim=-1)\n",
    "\n",
    "    # update context/output_so_far appending the new token\n",
    "    output_so_far = last if output_so_far is None else torch.cat((output_so_far, last), dim=1)\n",
    "\n",
    "    print(tokenizer.decode(output_so_far.tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197967b8-b937-454f-8cc7-1614b62b70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b99d16d1-8c9d-4eb7-ab96-f7d954312893",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wooseok/miniconda3/envs/mh/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n",
      "/home/wooseok/miniconda3/envs/mh/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /home/wooseok/miniconda3/envs/mh/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 6.1\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /home/wooseok/miniconda3/envs/mh/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda113_nocublaslt.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████| 33/33 [00:28<00:00,  1.16it/s]\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>tokenizer = AutoTokenizer.from_pretrained(<span style=\"color: #808000; text-decoration-color: #808000\">\"/home/wooseok/llama-7b-hf\"</span>)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 </span>cond_text = <span style=\"color: #808000; text-decoration-color: #808000\">'The movie was'</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>7 output_so_far = torch.tensor(tokenizer.encode(tokenizer.bos_token + cond_text),              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8 │   │   │   │   │   │   │    </span>device=device, dtype=torch.long).unsqueeze(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">9 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'torch'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m7\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0mtokenizer = AutoTokenizer.from_pretrained(\u001b[33m\"\u001b[0m\u001b[33m/home/wooseok/llama-7b-hf\u001b[0m\u001b[33m\"\u001b[0m)                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0mcond_text = \u001b[33m'\u001b[0m\u001b[33mThe movie was\u001b[0m\u001b[33m'\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m7 output_so_far = torch.tensor(tokenizer.encode(tokenizer.bos_token + cond_text),              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m8 \u001b[0m\u001b[2m│   │   │   │   │   │   │    \u001b[0mdevice=device, dtype=torch.long).unsqueeze(\u001b[94m0\u001b[0m)                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m9 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'torch'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/home/wooseok/llama-7b-hf\", \n",
    "                                             device_map=\"auto\", load_in_8bit=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/wooseok/llama-7b-hf\")\n",
    "\n",
    "cond_text = 'The movie was'\n",
    "output_so_far = torch.tensor(tokenizer.encode(tokenizer.bos_token + cond_text),\n",
    "                             device=device, dtype=torch.long).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cb5fd62-8beb-4312-bb86-e40ea0e0a0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭──────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                              <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #800080; text-decoration-color: #800080\">device</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.long<span style=\"font-weight: bold\">)</span>                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                             <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">▲</span>                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">IndentationError: </span>unexpected indent\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[91m╭──────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m\n",
       "\u001b[91m│\u001b[0m                              \u001b[33mdevice\u001b[0m=\u001b[35mdevice\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.long\u001b[1m)\u001b[0m                                    \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                             \u001b[1;91m▲\u001b[0m                                                                    \u001b[91m│\u001b[0m\n",
       "\u001b[91m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mIndentationError: \u001b[0munexpected indent\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.encode(tokenizer.bos_token + cond_text),\n",
    "                             device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "562eaa3b-ca5d-478b-8be0-9e359f2e95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device\n",
    "cond_text = 'The movie was'\n",
    "output_so_far = torch.tensor(tokenizer.encode(tokenizer.bos_token + cond_text),\n",
    "                             device=device, dtype=torch.long).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "360e957f-0b83-463b-a60f-6fa9b47352ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_so_far = torch.tensor(tokenizer.encode(tokenizer.bos_token + cond_text),\n",
    "                             device=device).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4540642-18e7-4856-9da6-7f7e1ae9cf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,   450, 14064,   471]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(output_so_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54eca435-c69e-4dcf-b653-79a23087aea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   450, 14064,   471]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1e1034c-12c1-4351-b253-5cc9b479b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "last = output_so_far[:, -1:] # 마지막 단어 # tensor([[23382]], device='cuda:0')\n",
    "\n",
    "# 시작할 때 이전단어들로 past 만들어주기\n",
    "past = model(output_so_far[:, :-1],return_dict =True)[\"past_key_values\"] # 이전 단어들을 input으로 넣어서 첫 past 만듬."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61c6d42f-4f83-424d-ae19-2e32516f32ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['logits', 'past_key_values'])\n"
     ]
    }
   ],
   "source": [
    "print(model(output_so_far[:, :-1],return_dict =True).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f38050e1-d5f8-4b42-878a-7d51e978fe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "last = output_so_far[:, -1:]\n",
    "past = model(output_so_far[:, :-1],return_dict =True)[\"past_key_values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5917b7f2-2526-48b0-a3d1-28464984734c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 , 2 , torch.Size([1, 32, 3, 128])\n"
     ]
    }
   ],
   "source": [
    "print(len(past),\",\",len(past[0]),\",\",past[0][0].shape) \n",
    "#layer수,key_value, torch.Size([batch_size, num_heads, sequence_length, embed_size_per_head]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a751ff64-baaf-48fb-8b12-94fb2e618393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[471]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc287c23-e0b9-4891-bbf0-58a1c977f4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   450, 14064]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_so_far[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "134f3adb-1add-4819-8ef7-c67b6f80ccc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 classifier                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'classifier'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 classifier                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'classifier'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8070d49a-6c85-4f02-97be-d757543b2d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 단어와, past_key_values 를 넣어서 , logit과 다음 past를 output. \n",
    "lm_output = model(last, past_key_values=past, return_dict =True,output_hidden_states=True)\n",
    "logits, past,hidden_states = (\n",
    "        lm_output[\"logits\"], # torch.Size([1, 1, 32000])\n",
    "        lm_output[\"past_key_values\"], \n",
    "        lm_output[\"hidden_states\"]) # 33, torch.Size([1, 1, 4096]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7e0741d-4b1c-4876-affb-67cc922a9152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([1, 4096]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states = hidden_states[-1]\n",
    "len(last_hidden_states),last_hidden_states[0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b08804a3-7447-464d-b515-be6c4d884a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, past = (\n",
    "        lm_output[\"logits\"], # torch.Size([1, 1, 32000])\n",
    "        lm_output[\"past_key_values\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cca5e0a-59ee-4bc2-87ea-8d15a59bef37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32000])\n",
      "32 2 torch.Size([1, 32, 4, 128])\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape) #(batch_size, sequence_length=1, config.vocab_size)\n",
    "print(len(past),len(past[0]),past[0][0].shape) #layer수,keyvalue, torch.Size([1, 32, 3, 128]) (batch_size, num_heads, sequence_length, embed_size_per_head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21b5d068-f874-482d-bfd2-e66ef3ea8392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' temperatute_scailing, repetition_penalty으로 pert_logits 건드리기'''\n",
    "pert_logits = logits[:, -1, :] / temperature  # + SMALL_CONST\n",
    "#print(pert_logits.shape) # torch.Size([1, 32000])\n",
    "#print(output_so_far[0])\n",
    "for token_idx in set(output_so_far[0].tolist()):\n",
    "    if pert_logits[0, token_idx] < 0:\n",
    "        pert_logits[0, token_idx] *= repetition_penalty\n",
    "    else:\n",
    "        pert_logits[0, token_idx] /= repetition_penalty\n",
    "''' temperatute_scailing, repetition_penalty 끝'''\n",
    "\n",
    "logits = top_k_filter(pert_logits, k=top_k)  # + SMALL_CONST\n",
    "probs = nn.functional.softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6a85cbb-620c-4a89-b6fe-811b280a667e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32000])\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape) #(batch_size, sequence_length=1, config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01c8723b-5f74-40b1-b621-6528002bd25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32000])\n"
     ]
    }
   ],
   "source": [
    "print(probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c88289d2-cab7-47f0-8a4e-bd3372d1fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample or greedy\n",
    "if sample:\n",
    "    last = torch.multinomial(probs, num_samples=1)\n",
    "else:\n",
    "    _, last = torch.topk(probs, k=1, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f27a1f60-3771-4624-94dc-de7b845c3055",
   "metadata": {},
   "outputs": [],
   "source": [
    "last = torch.topk(probs, k=1, dim=-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1c44890-1d4d-4c17-85eb-6c94312c80dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[263]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f422adbc-36fd-4814-a90d-24b7ce80b77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The movie was a\n"
     ]
    }
   ],
   "source": [
    "output_so_far = torch.cat((output_so_far, last), dim=1)\n",
    "\n",
    "print(tokenizer.decode(output_so_far.tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "986367c6-28bc-4229-8f08-8c4c74750fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The movie was a bit\n"
     ]
    }
   ],
   "source": [
    "lm_output = model(last, past_key_values=past, return_dict =True,output_hidden_states=True)\n",
    "logits, past = (\n",
    "        lm_output[\"logits\"], # torch.Size([1, 1, 32000])\n",
    "        lm_output[\"past_key_values\"],\n",
    "    )\n",
    "pert_logits = logits[:, -1, :] / temperature  # + SMALL_CONST\n",
    "#print(pert_logits.shape) # torch.Size([1, 32000])\n",
    "#print(output_so_far[0])\n",
    "for token_idx in set(output_so_far[0].tolist()):\n",
    "    if pert_logits[0, token_idx] < 0:\n",
    "        pert_logits[0, token_idx] *= repetition_penalty\n",
    "    else:\n",
    "        pert_logits[0, token_idx] /= repetition_penalty\n",
    "''' temperatute_scailing, repetition_penalty 끝'''\n",
    "\n",
    "logits = top_k_filter(pert_logits, k=top_k)  # + SMALL_CONST\n",
    "probs = nn.functional.softmax(logits, dim=-1)\n",
    "if sample:\n",
    "    last = torch.multinomial(probs, num_samples=1)\n",
    "else:\n",
    "    _, last = torch.topk(probs, k=1, dim=-1)\n",
    "output_so_far = torch.cat((output_so_far, last), dim=1)\n",
    "\n",
    "print(tokenizer.decode(output_so_far.tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61282a7f-d007-4354-a9db-49227b9b6d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The movie was a bit more\n"
     ]
    }
   ],
   "source": [
    "lm_output = model(last, past_key_values=past, return_dict =True,output_hidden_states=True)\n",
    "logits, past = (\n",
    "        lm_output[\"logits\"], # torch.Size([1, 1, 32000])\n",
    "        lm_output[\"past_key_values\"],\n",
    "    )\n",
    "pert_logits = logits[:, -1, :] / temperature  # + SMALL_CONST\n",
    "#print(pert_logits.shape) # torch.Size([1, 32000])\n",
    "#print(output_so_far[0])\n",
    "for token_idx in set(output_so_far[0].tolist()):\n",
    "    if pert_logits[0, token_idx] < 0:\n",
    "        pert_logits[0, token_idx] *= repetition_penalty\n",
    "    else:\n",
    "        pert_logits[0, token_idx] /= repetition_penalty\n",
    "''' temperatute_scailing, repetition_penalty 끝'''\n",
    "\n",
    "logits = top_k_filter(pert_logits, k=top_k)  # + SMALL_CONST\n",
    "probs = nn.functional.softmax(logits, dim=-1)\n",
    "if sample:\n",
    "    last = torch.multinomial(probs, num_samples=1)\n",
    "else:\n",
    "    _, last = torch.topk(probs, k=1, dim=-1)\n",
    "output_so_far = torch.cat((output_so_far, last), dim=1)\n",
    "\n",
    "print(tokenizer.decode(output_so_far.tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c69a00e-d994-477a-a475-9a30c0c8e98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The movie was a bit more fun\n"
     ]
    }
   ],
   "source": [
    "lm_output = model(last, past_key_values=past, return_dict =True,output_hidden_states=True)\n",
    "logits, past = (\n",
    "        lm_output[\"logits\"], # torch.Size([1, 1, 32000])\n",
    "        lm_output[\"past_key_values\"],\n",
    "    )\n",
    "pert_logits = logits[:, -1, :] / temperature  # + SMALL_CONST\n",
    "#print(pert_logits.shape) # torch.Size([1, 32000])\n",
    "#print(output_so_far[0])\n",
    "for token_idx in set(output_so_far[0].tolist()):\n",
    "    if pert_logits[0, token_idx] < 0:\n",
    "        pert_logits[0, token_idx] *= repetition_penalty\n",
    "    else:\n",
    "        pert_logits[0, token_idx] /= repetition_penalty\n",
    "''' temperatute_scailing, repetition_penalty 끝'''\n",
    "\n",
    "logits = top_k_filter(pert_logits, k=top_k)  # + SMALL_CONST\n",
    "probs = nn.functional.softmax(logits, dim=-1)\n",
    "if sample:\n",
    "    last = torch.multinomial(probs, num_samples=1)\n",
    "else:\n",
    "    _, last = torch.topk(probs, k=1, dim=-1)\n",
    "output_so_far = torch.cat((output_so_far, last), dim=1)\n",
    "\n",
    "print(tokenizer.decode(output_so_far.tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3fdf336-42f5-423c-9bce-b8af39e39d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The movie was a bit more funny\n"
     ]
    }
   ],
   "source": [
    "lm_output = model(last, past_key_values=past, return_dict =True,output_hidden_states=True)\n",
    "logits, past = (\n",
    "        lm_output[\"logits\"], # torch.Size([1, 1, 32000])\n",
    "        lm_output[\"past_key_values\"],\n",
    "    )\n",
    "pert_logits = logits[:, -1, :] / temperature  # + SMALL_CONST\n",
    "#print(pert_logits.shape) # torch.Size([1, 32000])\n",
    "#print(output_so_far[0])\n",
    "for token_idx in set(output_so_far[0].tolist()):\n",
    "    if pert_logits[0, token_idx] < 0:\n",
    "        pert_logits[0, token_idx] *= repetition_penalty\n",
    "    else:\n",
    "        pert_logits[0, token_idx] /= repetition_penalty\n",
    "''' temperatute_scailing, repetition_penalty 끝'''\n",
    "\n",
    "logits = top_k_filter(pert_logits, k=top_k)  # + SMALL_CONST\n",
    "probs = nn.functional.softmax(logits, dim=-1)\n",
    "if sample:\n",
    "    last = torch.multinomial(probs, num_samples=1)\n",
    "else:\n",
    "    _, last = torch.topk(probs, k=1, dim=-1)\n",
    "output_so_far = torch.cat((output_so_far, last), dim=1)\n",
    "\n",
    "print(tokenizer.decode(output_so_far.tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "317b5425-c9a8-4f8f-a9c3-e6226a8f0541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The movie was a bit more funny and\n"
     ]
    }
   ],
   "source": [
    "lm_output = model(last, past_key_values=past, return_dict =True,output_hidden_states=True)\n",
    "logits, past = (\n",
    "        lm_output[\"logits\"], # torch.Size([1, 1, 32000])\n",
    "        lm_output[\"past_key_values\"],\n",
    "    )\n",
    "pert_logits = logits[:, -1, :] / temperature  # + SMALL_CONST\n",
    "#print(pert_logits.shape) # torch.Size([1, 32000])\n",
    "#print(output_so_far[0])\n",
    "for token_idx in set(output_so_far[0].tolist()):\n",
    "    if pert_logits[0, token_idx] < 0:\n",
    "        pert_logits[0, token_idx] *= repetition_penalty\n",
    "    else:\n",
    "        pert_logits[0, token_idx] /= repetition_penalty\n",
    "''' temperatute_scailing, repetition_penalty 끝'''\n",
    "\n",
    "logits = top_k_filter(pert_logits, k=top_k)  # + SMALL_CONST\n",
    "probs = nn.functional.softmax(logits, dim=-1)\n",
    "if sample:\n",
    "    last = torch.multinomial(probs, num_samples=1)\n",
    "else:\n",
    "    _, last = torch.topk(probs, k=1, dim=-1)\n",
    "output_so_far = torch.cat((output_so_far, last), dim=1)\n",
    "\n",
    "print(tokenizer.decode(output_so_far.tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bc1a0bbe-3465-46c0-9d6d-816c706fbfcf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
       "    (layers): ModuleList(\n",
       "      (0): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (1): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (2): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (3): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (4): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (5): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (6): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (7): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (8): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (9): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (10): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (11): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (12): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (13): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (14): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (15): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (16): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (17): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (18): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (19): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (20): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (21): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (22): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (23): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (24): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (25): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (26): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (27): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (28): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (29): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (30): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (31): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e40ed-ae76-4248-a2a3-1103b68eccf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {
    "4625e472-cc8d-430d-8ac3-6fd61d3d311d.png": {
     "image/png": "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"
    },
    "d17e8edf-7163-42b8-a817-297c112d8ade.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "c9f5ac8c-8666-414c-80d0-d33597333ed3",
   "metadata": {},
   "source": [
    "## 2.2 섭동 줄 때\n",
    "\n",
    "![image.png](attachment:4625e472-cc8d-430d-8ac3-6fd61d3d311d.png)![image.png](attachment:d17e8edf-7163-42b8-a817-297c112d8ade.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1669230d-8245-4895-9b42-dcb2e731c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_past(\n",
    "    past,\n",
    "    model,\n",
    "    last,\n",
    "    unpert_past=None,\n",
    "    unpert_logits=None,\n",
    "    accumulated_hidden=None,\n",
    "    grad_norms=None,\n",
    "    stepsize=0.01,\n",
    "    one_hot_bows_vectors=None,\n",
    "    classifier=None,\n",
    "    class_label=None,\n",
    "    loss_type=0,\n",
    "    num_iterations=3,\n",
    "    horizon_length=1,\n",
    "    window_length=0,\n",
    "    decay=False,\n",
    "    gamma=1.5,\n",
    "    kl_scale=0.01,\n",
    "    perturb_layer = 100,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    # Generate inital perturbed past\n",
    "    qq= []\n",
    "    for i in range(len(past)):\n",
    "        qq.append(torch.stack([past[i][0],past[i][1]]))\n",
    "    past =tuple(qq)\n",
    "    grad_accumulator = [(np.zeros(p.shape).astype(\"float32\")) for p in past]\n",
    "\n",
    "    if accumulated_hidden is None:\n",
    "        accumulated_hidden = 0\n",
    "\n",
    "    if decay:\n",
    "        decay_mask = torch.arange(0.0, 1.0 + SMALL_CONST, 1.0 / (window_length))[1:]\n",
    "    else:\n",
    "        decay_mask = 1.0\n",
    "\n",
    "    # TODO fix this comment (SUMANTH)\n",
    "    # Generate a mask is gradient perturbated is based on a past window\n",
    "    _, _, _, curr_length, _ = past[0].shape\n",
    "\n",
    "    if curr_length > window_length and window_length > 0:\n",
    "        ones_key_val_shape = tuple(past[0].shape[:-2]) + (window_length,) + tuple(past[0].shape[-1:])\n",
    "\n",
    "        zeros_key_val_shape = tuple(past[0].shape[:-2]) + (curr_length - window_length,) + tuple(past[0].shape[-1:])\n",
    "\n",
    "        ones_mask = torch.ones(ones_key_val_shape)\n",
    "        ones_mask = decay_mask * ones_mask.permute(0, 1, 2, 4, 3)\n",
    "        ones_mask = ones_mask.permute(0, 1, 2, 4, 3)\n",
    "\n",
    "        window_mask = torch.cat((ones_mask, torch.zeros(zeros_key_val_shape)), dim=-2).to(device)\n",
    "    else:\n",
    "        window_mask = torch.ones_like(past[0]).to(device)\n",
    "\n",
    "    # accumulate perturbations for num_iterations\n",
    "    loss_per_iter = []\n",
    "    new_accumulated_hidden = None\n",
    "    for i in range(num_iterations):\n",
    "        print(\"Iteration \", i + 1)\n",
    "\n",
    "        if perturb_layer == 100:\n",
    "            curr_perturbation = [torch.from_numpy(p_).requires_grad_(True).to(device=device) for p_ in grad_accumulator]\n",
    "            # make sure p_.grad is not None\n",
    "            for p_ in curr_perturbation:\n",
    "                p_.retain_grad()\n",
    "        else:\n",
    "            target_index = 32 + perturb_layer\n",
    "            curr_perturbation = [torch.from_numpy(p_).requires_grad_(i == target_index).to(device=device) for i, p_ in enumerate(grad_accumulator)]\n",
    "            # make sure p_.grad is not None\n",
    "            for i, p_ in enumerate(curr_perturbation):\n",
    "                if i == target_index:\n",
    "                    p_.retain_grad()\n",
    "\n",
    "        # Compute hidden using perturbed past\n",
    "        perturbed_past = list(map(add, past, curr_perturbation))\n",
    "\n",
    "        for i in range(len(perturbed_past)):\n",
    "            perturbed_past[i] = perturbed_past[i].to(torch.float16)\n",
    "\n",
    "        _, _, _, curr_length, _ = curr_perturbation[0].shape\n",
    "        lm_output = model(last, past_key_values=perturbed_past,return_dict =True,output_hidden_states=True)\n",
    "        #print(len(perturbed_past),perturbed_past[0].shape)\n",
    "        all_logits, all_hidden = lm_output[\"logits\"], lm_output[\"hidden_states\"]\n",
    "        hidden = all_hidden[-1]\n",
    "        new_accumulated_hidden = accumulated_hidden + torch.sum(hidden, dim=1).detach()\n",
    "        # TODO: Check the layer-norm consistency of this with trained discriminator (Sumanth)\n",
    "        logits = all_logits[:, -1, :]\n",
    "        probs = nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "        loss = 0.0\n",
    "        loss_list = []\n",
    "        '''\n",
    "        if loss_type == PPLM_BOW or loss_type == PPLM_BOW_DISCRIM:\n",
    "            for one_hot_bow in one_hot_bows_vectors:\n",
    "                bow_logits = torch.mm(probs, torch.t(one_hot_bow))\n",
    "                bow_loss = -torch.log(torch.sum(bow_logits))\n",
    "                loss += bow_loss\n",
    "                loss_list.append(bow_loss)\n",
    "            print(\" pplm_bow_loss:\", loss.data.cpu().numpy())\n",
    "        '''\n",
    "        if loss_type == 2 or loss_type == 3:\n",
    "            ce_loss = nn.CrossEntropyLoss()\n",
    "            # TODO why we need to do this assignment and not just using unpert_past? (Sumanth)\n",
    "            curr_unpert_past = unpert_past\n",
    "            curr_probs = torch.unsqueeze(probs, dim=1)\n",
    "            wte = model.resize_token_embeddings()\n",
    "            for _ in range(horizon_length):\n",
    "                #print(curr_probs)\n",
    "                #print(wte.weight.data)\n",
    "                inputs_embeds = torch.matmul(curr_probs, wte.weight.data.float())\n",
    "                lm_output = model(past_key_values=curr_unpert_past, inputs_embeds=inputs_embeds,return_dict=True,output_hidden_states=True)\n",
    "                curr_all_logits, curr_unpert_past, curr_all_hidden = (\n",
    "                    lm_output[\"logits\"],\n",
    "                    lm_output[\"past_key_values\"],\n",
    "                    lm_output[\"hidden_states\"],\n",
    "                )\n",
    "                curr_logits = curr_all_logits[:, -1, :]\n",
    "                curr_probs = nn.functional.softmax(curr_logits, dim=-1)\n",
    "                curr_probs = torch.unsqueeze(curr_probs, dim=1)\n",
    "                curr_hidden = curr_all_hidden[-1]\n",
    "                new_accumulated_hidden = new_accumulated_hidden + torch.sum(curr_hidden, dim=1)\n",
    "            #print(classifier)\n",
    "            #print(new_accumulated_hidden.shape)\n",
    "            prediction = classifier(new_accumulated_hidden / (curr_length + 1 + horizon_length))\n",
    "\n",
    "            label = torch.tensor(prediction.shape[0] * [class_label], device=device, dtype=torch.long)\n",
    "            discrim_loss = ce_loss(prediction, label)\n",
    "            print(\" pplm_discrim_loss:\", discrim_loss.data.cpu().numpy())\n",
    "            loss += discrim_loss\n",
    "            loss_list.append(discrim_loss)\n",
    "\n",
    "        kl_loss = 0.0\n",
    "        if kl_scale > 0.0:\n",
    "            unpert_probs = nn.functional.softmax(unpert_logits[:, -1, :], dim=-1)\n",
    "            unpert_probs = unpert_probs + SMALL_CONST * (unpert_probs <= SMALL_CONST).float().to(device).detach()\n",
    "            correction = SMALL_CONST * (probs <= SMALL_CONST).float().to(device).detach()\n",
    "            corrected_probs = probs + correction.detach()\n",
    "            kl_loss = kl_scale * ((corrected_probs * (corrected_probs / unpert_probs).log()).sum())\n",
    "            print(\" kl_loss\", kl_loss.data.cpu().numpy())\n",
    "            loss += kl_loss\n",
    "\n",
    "        loss_per_iter.append(loss.data.cpu().numpy())\n",
    "        print(\" pplm_loss\", (loss - kl_loss).data.cpu().numpy())\n",
    "\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # calculate gradient norms\n",
    "        grad_norms = [\n",
    "            (torch.norm(p_.grad * window_mask) + SMALL_CONST) for index, p_ in enumerate(curr_perturbation)]\n",
    "\n",
    "        # normalize gradients\n",
    "        grad = [\n",
    "            -stepsize * (p_.grad * window_mask / grad_norms[index] ** gamma).data.cpu().numpy()\n",
    "            for index, p_ in enumerate(curr_perturbation)]\n",
    "        \n",
    "        # accumulate gradient\n",
    "        grad_accumulator = list(map(add, grad, grad_accumulator))\n",
    "        \n",
    "        # reset gradients, just to make sure\n",
    "        \n",
    "        for p_ in curr_perturbation:\n",
    "            p_.grad.data.zero_()\n",
    "\n",
    "        # removing past from the graph\n",
    "        new_past = []\n",
    "        for p_ in past:\n",
    "            new_past.append(p_.detach())\n",
    "        past = new_past\n",
    "\n",
    "    # apply the accumulated perturbations to the past\n",
    "    grad_accumulator = [torch.from_numpy(p_).requires_grad_(True).to(device=device) for p_ in grad_accumulator]\n",
    "    pert_past = list(map(add, past, grad_accumulator))\n",
    "    \n",
    "    return pert_past, new_accumulated_hidden, grad_norms, loss_per_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5736b06e-15e4-436d-b46e-7af201434e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                             | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1\n",
      "tensor([[[1.2863e-11, 3.0968e-13, 3.8057e-06,  ..., 2.3708e-10,\n",
      "          7.1894e-10, 3.0269e-09]]], device='cuda:0',\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "tensor([[ 9.8884e-05, -2.3329e-04,  5.8460e-04,  ..., -3.4237e-04,\n",
      "          5.9724e-05, -1.1957e-04],\n",
      "        [ 1.5289e-02, -1.2154e-02,  1.2512e-02,  ...,  1.3092e-02,\n",
      "          7.2174e-03, -6.8045e-04],\n",
      "        [ 1.7433e-03,  1.7633e-03, -1.4465e-02,  ..., -1.1444e-02,\n",
      "         -1.2665e-02,  3.7289e-04],\n",
      "        ...,\n",
      "        [-9.0179e-03,  3.0807e-02, -1.6708e-02,  ..., -1.2680e-02,\n",
      "          1.0437e-02,  4.2343e-03],\n",
      "        [-1.1368e-02, -1.4801e-02, -3.5667e-03,  ...,  6.5308e-03,\n",
      "         -2.2263e-02, -6.1455e-03],\n",
      "        [-1.3992e-02,  1.6985e-03, -2.1469e-02,  ...,  1.3527e-02,\n",
      "          2.8290e-02, -8.9111e-03]], device='cuda:0', dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wooseok/miniconda3/envs/mh/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:298: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "  0%|                                                                                             | 0/5 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Half",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m accumulated_hidden \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(accumulated_hidden, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#torch.Size([1, 4096])\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     pert_past, _, grad_norms, loss_this_iter \u001b[38;5;241m=\u001b[39m \u001b[43mperturb_past\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43munpert_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpert_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43munpert_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpert_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulated_hidden\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccumulated_hidden\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_norms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstepsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_stepsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mone_hot_bows_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mone_hot_bows_vectors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhorizon_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhorizon_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkl_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkl_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mperturb_layer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mperturb_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     loss_in_time\u001b[38;5;241m.\u001b[39mappend(loss_this_iter)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[52], line 111\u001b[0m, in \u001b[0;36mperturb_past\u001b[0;34m(past, model, last, unpert_past, unpert_logits, accumulated_hidden, grad_norms, stepsize, one_hot_bows_vectors, classifier, class_label, loss_type, num_iterations, horizon_length, window_length, decay, gamma, kl_scale, perturb_layer, device)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m(wte\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m    110\u001b[0m inputs_embeds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(curr_probs, wte\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m--> 111\u001b[0m lm_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_unpert_past\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m curr_all_logits, curr_unpert_past, curr_all_hidden \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    113\u001b[0m     lm_output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    114\u001b[0m     lm_output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    115\u001b[0m     lm_output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    117\u001b[0m curr_logits \u001b[38;5;241m=\u001b[39m curr_all_logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "File \u001b[0;32m~/miniconda3/envs/mh/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/mh/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/mh/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:824\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    822\u001b[0m     logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    825\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    827\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mh/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/mh/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/mh/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Half"
     ]
    }
   ],
   "source": [
    "cond_text = 'I am studying'\n",
    "\n",
    "raw_text = cond_text\n",
    "tokenized_cond_text = tokenizer.encode(tokenizer.bos_token + raw_text)\n",
    "\n",
    "context = tokenized_cond_text\n",
    "\n",
    "output_so_far = None\n",
    "past = None\n",
    "perturb=True\n",
    "if context:\n",
    "    context_t = torch.tensor(context, device=device, dtype=torch.long)\n",
    "    while len(context_t.shape) < 2:\n",
    "        context_t = context_t.unsqueeze(0)\n",
    "    output_so_far = context_t # tensor([[    1,   306,   626, 23382]], device='cuda:0')\n",
    "\n",
    "grad_norms = None\n",
    "last = None\n",
    "unpert_discrim_loss = 0\n",
    "loss_in_time = []\n",
    "for i in trange(length, ascii=True):\n",
    "    \n",
    "    # Get past/probs for current output, except for last word\n",
    "    # Note that GPT takes 2 inputs: past + current_token\n",
    "\n",
    "    # run model forward to obtain unperturbed\n",
    "    if past is None and output_so_far is not None: # 제일 처음에만 얘한테 걸림. \n",
    "        \n",
    "        last = output_so_far[:, -1:] # 마지막 단어\n",
    "        if output_so_far.shape[1] > 1:\n",
    "            past = model(output_so_far[:, :-1],return_dict =True)[\"past_key_values\"] # 이전 단어들을 input으로 넣어서 첫 past 만듬. \n",
    "            #print(len(past),len(past[0]),past[0][0].shape) #layer수,keyvalue, torch.Size([1, 32, 3, 128]) (batch_size, num_heads, sequence_length, embed_size_per_head)\n",
    "\n",
    "    lm_output = model(output_so_far,return_dict =True,output_hidden_states=True)\n",
    "    unpert_logits, unpert_past, unpert_all_hidden = (\n",
    "        lm_output[\"logits\"], #Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax). #(batch_size, sequence_length, vocab_size)\n",
    "        lm_output[\"past_key_values\"], # #layer수,keyvalue, (batch_size, num_heads, sequence_length, embed_size_per_head(key 벡터의 길이))\n",
    "        lm_output[\"hidden_states\"], #layer 수+1, (batch_size, sequence_length, hidden_size(sequence를 이 벡터 길이만큼 표현하겠다)).\n",
    "    )\n",
    "    #print(unpert_logits.shape) #(batch_size, sequence_length, config.vocab_size)\n",
    "    #print(len(unpert_past),len(unpert_past[0]),unpert_past[0][0].shape)\n",
    "    #print(len(unpert_all_hidden),unpert_all_hidden[0].shape)  33 torch.Size([1, 4, 4096])\n",
    "    unpert_last_hidden = unpert_all_hidden[-1]\n",
    "    #print(unpert_last_hidden.shape) #torch.Size([1, 4, 4096])\n",
    "   \n",
    "    current_stepsize = stepsize\n",
    "\n",
    "    # modify the past if necessary\n",
    "    if not perturb or num_iterations == 0:\n",
    "        pert_past = past\n",
    "    \n",
    "    ####################################### perturb 하는 부분 #################################\n",
    "    else:\n",
    "            accumulated_hidden = unpert_last_hidden[:, :-1, :] #torch.Size([1, 3, 4096])\n",
    "            accumulated_hidden = torch.sum(accumulated_hidden, dim=1) #torch.Size([1, 4096])\n",
    "\n",
    "            if past is not None:\n",
    "                pert_past, _, grad_norms, loss_this_iter = perturb_past(\n",
    "                    past,\n",
    "                    model,\n",
    "                    last,\n",
    "                    unpert_past=unpert_past,\n",
    "                    unpert_logits=unpert_logits,\n",
    "                    accumulated_hidden=accumulated_hidden,\n",
    "                    grad_norms=grad_norms,\n",
    "                    stepsize=current_stepsize,\n",
    "                    one_hot_bows_vectors=one_hot_bows_vectors,\n",
    "                    classifier=classifier,\n",
    "                    class_label=class_label,\n",
    "                    loss_type=loss_type,\n",
    "                    num_iterations=num_iterations,\n",
    "                    horizon_length=horizon_length,\n",
    "                    window_length=window_length,\n",
    "                    decay=decay,\n",
    "                    gamma=gamma,\n",
    "                    kl_scale=kl_scale,\n",
    "                    perturb_layer = perturb_layer,\n",
    "                    device=device,\n",
    "                )\n",
    "                loss_in_time.append(loss_this_iter)\n",
    "            else:\n",
    "                pert_past = past         \n",
    "    ####################################### perturb 하는 부분 끝 #################################\n",
    "    \n",
    "    ''' past type 맞춰주기'''\n",
    "    qqqq= []\n",
    "    for i in range(len(pert_past)):\n",
    "        qqqq.append(torch.stack([pert_past[i][0],pert_past[i][1]]))\n",
    "    pert_past = qqqq\n",
    "    for i in range(len(pert_past)):\n",
    "        pert_past[i] = pert_past[i].to(torch.float16)\n",
    "    '''past type 맞춰주기 끝''' \n",
    "    \n",
    "    #print(last)\n",
    "    lm_output = model(last, past_key_values=pert_past,return_dict =True,output_hidden_states=True) # 마지막 단어와,past를 input으로 넣음. \n",
    "    pert_logits, past = (\n",
    "        lm_output[\"logits\"], # torch.Size([1, 1, 32000])\n",
    "        lm_output[\"past_key_values\"],\n",
    "    )\n",
    "    #print(pert_logits.shape) #(batch_size, sequence_length=1, config.vocab_size)\n",
    "    #print(len(past),len(past[0]),past[0][0].shape)\n",
    "    \n",
    "    ''' temperatute_scailing, repetition_penalty으로 pert_logits 건드리기'''\n",
    "    pert_logits = pert_logits[:, -1, :] / temperature  # + SMALL_CONST\n",
    "    #print(pert_logits.shape) # torch.Size([1, 32000])\n",
    "    #print(output_so_far[0])\n",
    "    for token_idx in set(output_so_far[0].tolist()):\n",
    "        if pert_logits[0, token_idx] < 0:\n",
    "            pert_logits[0, token_idx] *= repetition_penalty\n",
    "        else:\n",
    "            pert_logits[0, token_idx] /= repetition_penalty\n",
    "    ''' temperatute_scailing, repetition_penalty 끝'''\n",
    "    \n",
    "    pert_probs = nn.functional.softmax(pert_logits, dim=-1)\n",
    "    \n",
    "    if classifier is not None:\n",
    "        ce_loss = nn.CrossEntropyLoss()\n",
    "        # print(torch.mean(unpert_last_hidden, dim=1).shape) # torch.Size([1, 4096])\n",
    "        prediction = classifier(torch.mean(unpert_last_hidden, dim=1))\n",
    "        label = torch.tensor([class_label], device=device, dtype=torch.long)\n",
    "        unpert_discrim_loss = ce_loss(prediction, label)\n",
    "        print(\"unperturbed discrim loss\", unpert_discrim_loss.data.cpu().numpy())\n",
    "    else:\n",
    "        unpert_discrim_loss = 0\n",
    "\n",
    "    # Fuse the modified model and original model\n",
    "    if perturb: \n",
    "        unpert_probs = nn.functional.softmax(unpert_logits[:, -1, :], dim=-1)\n",
    "\n",
    "        pert_probs = (pert_probs**gm_scale) * (unpert_probs ** (1 - gm_scale))  # + SMALL_CONST\n",
    "        pert_probs = top_k_filter(pert_probs, k=top_k, probs=True)  # + SMALL_CONST\n",
    "\n",
    "        # rescale\n",
    "        if torch.sum(pert_probs) <= 1:\n",
    "            pert_probs = pert_probs / torch.sum(pert_probs)\n",
    "    else:\n",
    "        pert_logits = top_k_filter(pert_logits, k=top_k)  # + SMALL_CONST\n",
    "        pert_probs = nn.functional.softmax(pert_logits, dim=-1)\n",
    "\n",
    "    # sample or greedy\n",
    "    if sample:\n",
    "        last = torch.multinomial(pert_probs, num_samples=1)\n",
    "\n",
    "    else:\n",
    "        _, last = torch.topk(pert_probs, k=1, dim=-1)\n",
    "\n",
    "    # update context/output_so_far appending the new token\n",
    "    output_so_far = last if output_so_far is None else torch.cat((output_so_far, last), dim=1)\n",
    "\n",
    "    print(tokenizer.decode(output_so_far.tolist()[0]))\n",
    "    print(\"$$$$$$$$$$$$\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d57338a-34a1-4b2c-a198-dac7bb8cc567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 4.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= torch.tensor([[3,4]],dtype=torch.float16)\n",
    "a.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b37b1ce-5681-49d7-a298-307f9be094f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return pert_past, new_accumulated_hidden, grad_norms, loss_per_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9090024e-4172-4a76-8e56-0c6f32e3ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_output= model(last, past_key_values=past,\n",
    "                 return_dict=True,output_hidden_states=True)  \n",
    "logit, past = (\n",
    "    lm_output[\"logits\"], \n",
    "    lm_output[\"past_key_values\"]) \n",
    "\n",
    "probs = nn.functional.softmax(logit[:,-1,:], dim=-1)\n",
    "last = torch.topk(probs, k=1, dim=-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b816f9-9545-4c93-9a9f-4590bfde8dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lm_output = model(last, past_key_values=perturbed_past\n",
    "                  ,return_dict =True)\n",
    "pert_logits, past = (\n",
    "    lm_output[\"logits\"],\n",
    "    lm_output[\"past_key_values\"])\n",
    "pert_probs = nn.functional.softmax(pert_logits, dim=-1)\n",
    "pert_last = torch.topk(pert_probs, k=1, dim=-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18e44726-6be3-4579-aa70-c03f6355bd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pert_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f35ad6bc-a323-47a6-bc01-1ce6093b2611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(unpert_last_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "caabdb28-dd5c-45c2-95e9-0ba53c20d7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(accumulated_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2a1c7a3d-9f18-48b5-8c49-912e03e36ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated_hidden = unpert_last_hidden[:, :-1, :] #torch.Size([1, 3, 4096])\n",
    "#print(accumulated_hidden.shape)\n",
    "accumulated_hidden = torch.sum(accumulated_hidden, dim=1) #torch.Size([1, 4096])\n",
    "#print(accumulated_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "56eefd3c-7498-41ff-be39-1516d2938545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if curr_length > window_length and window_length > 0:\n",
    "    ones_key_val_shape = tuple(past[0].shape[:-2]) + (window_length,) + tuple(past[0].shape[-1:])\n",
    "\n",
    "    zeros_key_val_shape = tuple(past[0].shape[:-2]) + (curr_length - window_length,) + tuple(past[0].shape[-1:])\n",
    "\n",
    "    ones_mask = torch.ones(ones_key_val_shape)\n",
    "    ones_mask = decay_mask * ones_mask.permute(0, 1, 2, 4, 3)\n",
    "    ones_mask = ones_mask.permute(0, 1, 2, 4, 3)\n",
    "\n",
    "    window_mask = torch.cat((ones_mask, torch.zeros(zeros_key_val_shape)), dim=-2).to(device)\n",
    "else:\n",
    "    window_mask = torch.ones_like(past[0]).to(device)\n",
    "decay_mask = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6c290f6f-bb37-46fb-bb76-f5683c6c278b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 torch.Size([2, 1, 32, 4, 128])\n"
     ]
    }
   ],
   "source": [
    "qq= []\n",
    "for i in range(len(past)):\n",
    "    qq.append(torch.stack([past[i][0],past[i][1]]))\n",
    "past =tuple(qq)\n",
    "print(len(past),past[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59a635e1-ce25-44f1-b4ac-2049637aca4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate inital perturbed past\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m grad_accumulator \u001b[38;5;241m=\u001b[39m [(np\u001b[38;5;241m.\u001b[39mzeros(p\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m past] \u001b[38;5;66;03m# 32 (2, 1, 32, 3, 128)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accumulated_hidden \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     accumulated_hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[46], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate inital perturbed past\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m grad_accumulator \u001b[38;5;241m=\u001b[39m [(np\u001b[38;5;241m.\u001b[39mzeros(\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m past] \u001b[38;5;66;03m# 32 (2, 1, 32, 3, 128)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accumulated_hidden \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     accumulated_hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Generate inital perturbed past\n",
    "\n",
    "grad_accumulator = [(np.zeros(p.shape).astype(\"float32\")) for p in past] # 32 (2, 1, 32, 3, 128)\n",
    "\n",
    "if accumulated_hidden is None:\n",
    "    accumulated_hidden = 0\n",
    "\n",
    "# TODO fix this comment (SUMANTH)\n",
    "# Generate a mask is gradient perturbated is based on a past window\n",
    "_, _, _, curr_length, _ = past[0].shape\n",
    "\n",
    "# accumulate perturbations for num_iterations\n",
    "loss_per_iter = []\n",
    "new_accumulated_hidden = None\n",
    "\n",
    "'''grad_accumulator update (델타 H_t update)과정'''\n",
    "for i in range(num_iterations):\n",
    "    print(\"Iteration \", i + 1)\n",
    "\n",
    "    curr_perturbation = [torch.from_numpy(p_).requires_grad_(True).to(device=device) for p_ in grad_accumulator]\n",
    "    #numpy에서 tensor로 바꿔주고, requires_grad 켜주고, gpu 올려주고. \n",
    "    '''tensor의 gradient를 구할 때에는 다음 조건들이 만족되어야 gradient를 구할 수 있습니다.\n",
    "        1) tensor의 옵션이 requires_grad = True 로 설정되어 있어야 합니다. (tensor의 기본 값은 requires_grad = False 입니다.)'''\n",
    "    for p_ in curr_perturbation:\n",
    "        p_.retain_grad() \n",
    "        '''해당 변수에 대한 gradient 연산을 기억 -> \n",
    "        이것을 하지 않으면 중간 변수에 대한 gradient는 저장 안됨.\n",
    "        reatain_grad()를 통해 gradient가 사라지는 것을 예방할 수 있다. \n",
    "        계산그래프에서 leaf node가 아닌 tensor의 gradient는 계산 후 날라가는데, \n",
    "        retain_grad를 통해 날라가지 않고 붙잡을 수 있다.'''\n",
    "\n",
    "    # Compute hidden using perturbed past\n",
    "    \n",
    "    perturbed_past = list(map(add, past, curr_perturbation))\n",
    "    #print(len(perturbed_past),perturbed_past[0].shape)\n",
    "    for i in range(len(perturbed_past)):\n",
    "        perturbed_past[i] = perturbed_past[i].to(torch.float16)\n",
    "\n",
    "    _, _, _, curr_length, _ = curr_perturbation[0].shape\n",
    "    lm_output = model(last, past_key_values=perturbed_past,return_dict =True,output_hidden_states=True)\n",
    "    \n",
    "    all_logits, all_hidden = lm_output[\"logits\"], lm_output[\"hidden_states\"] # torch.Size([1, 1, 32000]) , 33 torch.Size([1, 1, 4096])\n",
    "    print(\",ㅇㅂㅈㅂㅈㅂ\",all_logits.shape)\n",
    "    print(len(all_hidden),all_hidden[0].shape)\n",
    "    hidden = all_hidden[-1]\n",
    "    new_accumulated_hidden = accumulated_hidden + torch.sum(hidden, dim=1).detach() #torch.Size([1, 4096])\n",
    "    #여기까지 h_t +h_{t+1}\n",
    "    \n",
    "    logits = all_logits[:, -1, :] \n",
    "    print(logits.shape)\n",
    "    probs = nn.functional.softmax(logits, dim=-1)  #p_{t+1}\n",
    "    \n",
    "    ######loss 구하기##########\n",
    "    loss = 0.0\n",
    "    loss_list = []\n",
    "    '''1. loss의 첫째항 시작'''\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    curr_unpert_past = unpert_past\n",
    "    curr_probs = torch.unsqueeze(probs, dim=1)\n",
    "    wte = model.resize_token_embeddings() #word token embeddings\n",
    "    \n",
    "    #print(\"curr_probs\",curr_probs.shape) # torch.Size([1, 1, 32000])\n",
    "    print(type(curr_probs))\n",
    "    print(type(wte.weight.data))\n",
    "    inputs_embeds = torch.matmul(curr_probs, wte.weight.data) # 32000-> 4096\n",
    "    #print(\"inputs_embeds\",inputs_embeds) \n",
    "    #print(inputs_embeds.shape) # torch.Size([1, 1, 4096])\n",
    "    #curr_unpert_past : H_{t+1}\n",
    "    # inputs_embeds: x_{t+1} (approximated)\n",
    "    lm_output = model(past_key_values=curr_unpert_past, inputs_embeds=inputs_embeds,return_dict=True,output_hidden_states=True)\n",
    "    curr_all_logits, curr_unpert_past, curr_all_hidden = (\n",
    "        lm_output[\"logits\"], \n",
    "        lm_output[\"past_key_values\"], \n",
    "        lm_output[\"hidden_states\"], # h_{t+2}\n",
    "    )\n",
    "    print(\"zzzzzzzzzzzzzzzzzzㅋㅋ\",curr_all_logits.shape)\n",
    "    #print(len(curr_unpert_past),len(curr_unpert_past[0]),curr_unpert_past[0][0].shape)\n",
    "\n",
    "    curr_logits = curr_all_logits[:, -1, :]\n",
    "    curr_probs = nn.functional.softmax(curr_logits, dim=-1)\n",
    "    curr_probs = torch.unsqueeze(curr_probs, dim=1) \n",
    "    curr_hidden = curr_all_hidden[-1]\n",
    "    #print(curr_hidden.shape) #torch.Size([1, 1, 4096])\n",
    "    new_accumulated_hidden = new_accumulated_hidden + torch.sum(curr_hidden, dim=1) # torch.Size([1, 4096])\n",
    "    #print(classifier)\n",
    "    print(new_accumulated_hidden.shape,\"zzzzzzzzzzzzzzzz\")\n",
    "    \n",
    "    prediction = classifier(new_accumulated_hidden / (curr_length + 1 + horizon_length))\n",
    "    print(\"ㅇㅇ\",prediction)\n",
    "    label = torch.tensor(prediction.shape[0] * [class_label], device=device, dtype=torch.long)\n",
    "    discrim_loss = ce_loss(prediction, label) # likelihood \n",
    "    print(\" pplm_discrim_loss:\", discrim_loss.data.cpu().numpy())\n",
    "    loss += discrim_loss\n",
    "    loss_list.append(discrim_loss)\n",
    "    '''1. loss의 첫째항 끝'''\n",
    "    \n",
    "    '''2. loss의 둘째항 시작'''\n",
    "    kl_loss = 0.0\n",
    "    if kl_scale > 0.0:\n",
    "        unpert_probs = nn.functional.softmax(unpert_logits[:, -1, :], dim=-1)\n",
    "        unpert_probs = unpert_probs + SMALL_CONST * (unpert_probs <= SMALL_CONST).float().to(device).detach()\n",
    "        correction = SMALL_CONST * (probs <= SMALL_CONST).float().to(device).detach()\n",
    "        corrected_probs = probs + correction.detach()\n",
    "        kl_loss = kl_scale * ((corrected_probs * (corrected_probs / unpert_probs).log()).sum())\n",
    "        print(\" kl_loss\", kl_loss.data.cpu().numpy())\n",
    "        loss += kl_loss\n",
    "    '''2. loss의 둘째항 끝'''\n",
    "    \n",
    "    loss_per_iter.append(loss.data.cpu().numpy())\n",
    "    #print(\" pplm_loss\", (loss - kl_loss).data.cpu().numpy())\n",
    "\n",
    "    # compute gradients\n",
    "    loss.backward() # gradient 계산 , p_.grad는 gradient 계산값\n",
    "\n",
    "    # calculate gradient norms\n",
    "    grad_norms = [\n",
    "        (torch.norm(p_.grad) + SMALL_CONST) for index, p_ in enumerate(curr_perturbation)]\n",
    "\n",
    "    # normalize gradients\n",
    "    grad = [\n",
    "        -stepsize * (p_.grad  / grad_norms[index] ** gamma).data.cpu().numpy()\n",
    "        for index, p_ in enumerate(curr_perturbation)]\n",
    "\n",
    "    # accumulate gradient\n",
    "    grad_accumulator = list(map(add, grad, grad_accumulator))\n",
    "\n",
    "    # reset gradients, just to make sure\n",
    "\n",
    "    for p_ in curr_perturbation:\n",
    "        p_.grad.data.zero_()\n",
    "\n",
    "    # removing past from the graph\n",
    "    new_past = []\n",
    "    for p_ in past:\n",
    "        new_past.append(p_.detach())\n",
    "    past = new_past\n",
    "'''grad_accumulator update 과정 끝 '''\n",
    "\n",
    "# apply the accumulated perturbations to the past\n",
    "\n",
    "grad_accumulator = [torch.from_numpy(p_).requires_grad_(True).to(device=device) for p_ in grad_accumulator]\n",
    "\n",
    "pert_past = list(map(add, past, grad_accumulator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ae6d0f6a-efb9-4086-b520-15603d06e995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_accumulator = [(np.zeros(p.shape).astype(\"float32\")) for p in past]\n",
    "grad_accumulator[0][0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "504d5169-68f1-4934-af6c-9193a790801a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float32,\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_perturbation = [torch.from_numpy(p_).requires_grad_(True).to(device=device) for p_ in grad_accumulator]\n",
    "curr_perturbation[0][0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e8d7e0b3-df65-4c4b-9d8d-59aa3a5fbc05",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0557, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0478, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0780, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.1556, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.1485, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.1387, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.1226, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.1126, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0964, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0919, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0902, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.1007, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.1021, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.1069, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0972, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.1018, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.1016, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0983, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0909, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0807, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0822, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0791, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0686, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0750, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0819, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0765, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0758, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0732, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0787, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0857, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0901, device='cuda:0', dtype=torch.float32),\n",
       " tensor(0.0810, device='cuda:0', dtype=torch.float32)]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_accumulator = [(np.zeros(p.shape).astype(\"float32\")) for p in past]\n",
    "    \n",
    "for i in range(num_iterations):\n",
    "    curr_perturbation = [torch.from_numpy(p_).requires_grad_(True).to(device=device) for p_ in grad_accumulator]\n",
    "    \n",
    "    for p_ in curr_perturbation:\n",
    "        p_.retain_grad() \n",
    "    \n",
    "    # accumulated_hidden_average 구하기\n",
    "    perturbed_past = list(map(add, past, curr_perturbation))     \n",
    "    \n",
    "    _, _, _, curr_length, _ = curr_perturbation[0].shape\n",
    "    lm_output = model(last, past_key_values=perturbed_past,return_dict =True,output_hidden_states=True)\n",
    "    \n",
    "    all_logits, all_hidden = (\n",
    "        lm_output[\"logits\"], # torch.Size([1, 1, 32000])\n",
    "        lm_output[\"hidden_states\"])  #33 torch.Size([1, 1, 4096]) h_{t+1}\n",
    "    \n",
    "    hidden = all_hidden[-1] \n",
    "    new_accumulated_hidden = accumulated_hidden + torch.sum(hidden, dim=1).detach() #torch.Size([1, 4096])\n",
    "    #여기까지 h_t +h_{t+1}\n",
    "    \n",
    "    logits = all_logits[:, -1, :] \n",
    "    probs = nn.functional.softmax(logits, dim=-1)  #p_{t+1}\n",
    "    \n",
    "    curr_unpert_past = unpert_past\n",
    "    curr_probs = torch.unsqueeze(probs, dim=1) # torch.Size([1, 1, 32000])\n",
    "    wte = model.resize_token_embeddings() #word token embeddings # 32000-> 4096\n",
    "    \n",
    "    inputs_embeds = torch.matmul(curr_probs, wte.weight.data) # torch.Size([1, 1, 4096])\n",
    "    \n",
    "    #curr_unpert_past : H_{t+1}\n",
    "    # inputs_embeds: x_{t+1} (approximated)\n",
    "    lm_output = model(past_key_values=curr_unpert_past, inputs_embeds=inputs_embeds,return_dict=True,output_hidden_states=True)\n",
    "    curr_all_logits, curr_unpert_past, curr_all_hidden = (\n",
    "        lm_output[\"logits\"], \n",
    "        lm_output[\"past_key_values\"], \n",
    "        lm_output[\"hidden_states\"]) # h_{t+2} \n",
    "    \n",
    "    curr_hidden = curr_all_hidden[-1] #torch.Size([1, 1, 4096])\n",
    "    new_accumulated_hidden = new_accumulated_hidden + torch.sum(curr_hidden, dim=1) # torch.Size([1, 4096])\n",
    "    accumulated_hidden_average = new_accumulated_hidden/(curr_length+1)\n",
    "    \n",
    "    #loss 구하기 \n",
    "    prediction = classifier(accumulated_hidden_average)\n",
    "\n",
    "    label = torch.tensor(prediction.shape[0] * [class_label], device=device, dtype=torch.long)\n",
    "\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    loss = ce_loss(prediction, label)\n",
    "\n",
    "    # compute gradients\n",
    "    loss.backward() # gradient 계산 , p_.grad는 gradient 계산값\n",
    "\n",
    "    # calculate gradient norms\n",
    "    grad_norms = [(torch.norm(p_.grad) + SMALL_CONST) for index, p_ in enumerate(curr_perturbation)]\n",
    "    \n",
    "    # normalize gradients\n",
    "    grad = [-stepsize * (p_.grad  / grad_norms[index] ** gamma).data.cpu().numpy()\n",
    "        for index, p_ in enumerate(curr_perturbation)]\n",
    "\n",
    "    # accumulate gradient\n",
    "    grad_accumulator = list(map(add, grad, grad_accumulator))\n",
    "\n",
    "\n",
    "pert_past = list(map(add, past, grad_accumulator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6c2fc028-090c-4482-bd20-a31c9a032c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(curr_all_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "826095af-da68-46f6-8c6f-75ccdc6b7e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturb_layer =11\n",
    "list(range(perturb_layer-11,perturb_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d1fde750-84c3-4833-8616-2b12eb5fc358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0538, -1.0723,  0.2404,  ...,  0.8218,  2.9785,  2.0508]],\n",
       "       device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(curr_hidden, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "fe8a9245-ade2-4a31-903a-e6f0a0f89605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0538, -1.0723,  0.2404,  ...,  0.8218,  2.9785,  2.0508]]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "1c9e0398-3e7f-44fb-9dac-74ec2ceac401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">21</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">'</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">19 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">'''</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">20 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>21 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>prediction = classifier(accumulated_hidden_average)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">23 │   </span>label = torch.tensor(prediction.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>] * [class_label], device=device, dtype=torch    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'accumulated_hidden_average'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m21\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m'\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m19 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m'''\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m20 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m21 \u001b[2m│   \u001b[0mprediction = classifier(accumulated_hidden_average)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m22 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m23 \u001b[0m\u001b[2m│   \u001b[0mlabel = torch.tensor(prediction.shape[\u001b[94m0\u001b[0m] * [class_label], device=device, dtype=torch    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m24 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'accumulated_hidden_average'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grad_accumulator = [(np.zeros(p.shape).astype(\"float32\")) for p in past]\n",
    "\n",
    "target_index = list(range(0,11))\n",
    "for i in range(num_iterations):\n",
    "    curr_perturbation = [torch.from_numpy(p_).requires_grad_(i in target_index).to(device=device) for i, p_ in enumerate(grad_accumulator)]\n",
    "    \n",
    "    for i, p_ in enumerate(curr_perturbation):\n",
    "        if i in target_index:\n",
    "            p_.retain_grad()\n",
    "    \n",
    "    # accumulated_hidden_average 구하기\n",
    "    perturbed_past = list(map(add, past, curr_perturbation))     \n",
    "    '''\n",
    "    ...........................\n",
    "    '''\n",
    "    \n",
    "    prediction = classifier(accumulated_hidden_average)\n",
    "\n",
    "    label = torch.tensor(prediction.shape[0] * [class_label], device=device, dtype=torch.long)\n",
    "\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    loss = ce_loss(prediction, label)\n",
    "\n",
    "    # compute gradients\n",
    "    loss.backward() # gradient 계산 , p_.grad는 gradient 계산값\n",
    "\n",
    "    # calculate gradient norms\n",
    "    grad_norms = [(torch.norm(p_.grad * window_mask) + SMALL_CONST) if index in target_index \n",
    "                  else SMALL_CONST for index, p_ in enumerate(curr_perturbation)]\n",
    "\n",
    "    # normalize gradients\n",
    "    grad = [-stepsize * (p_.grad * window_mask / grad_norms[index] ** gamma).data.cpu().numpy() if index in target_index \n",
    "            else np.zeros_like(p_.cpu())\n",
    "        for index, p_ in enumerate(curr_perturbation)]\n",
    "\n",
    "    # accumulate gradient\n",
    "    grad_accumulator = list(map(add, grad, grad_accumulator))\n",
    "\n",
    "pert_past = list(map(add, past, grad_accumulator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "fa12c49e-d227-4095-a84f-179b2e3496ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32),\n",
       " tensor(0., device='cuda:0', dtype=torch.float32)]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_norms = [torch.norm(p_.grad) for index, p_ in enumerate(curr_perturbation)]\n",
    "grad_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ffae9c8-103d-441d-ac9b-ad0e628dbe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_norms = [\n",
    "        (torch.norm(p_.grad * window_mask) + SMALL_CONST) for index, p_ in enumerate(curr_perturbation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b788e575-da7b-4935-ad31-d5ff9399e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_norms_m = [\n",
    "        (torch.norm(p_.grad) + SMALL_CONST) for index, p_ in enumerate(curr_perturbation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b45b3d9f-bd6f-485b-8699-aeaf3ada0372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(p_.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0e2f6d79-4cf4-4b97-af95-4a506b7eb238",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 p_.grad  / grad_norms[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>] ** gamma                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span>unsupported operand <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">type</span><span style=\"font-weight: bold\">(</span>s<span style=\"font-weight: bold\">)</span> for <span style=\"color: #800080; text-decoration-color: #800080\">/</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'NoneType'</span> and <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 p_.grad  / grad_norms[\u001b[94m0\u001b[0m] ** gamma                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0munsupported operand \u001b[1;35mtype\u001b[0m\u001b[1m(\u001b[0ms\u001b[1m)\u001b[0m for \u001b[35m/\u001b[0m: \u001b[32m'NoneType'\u001b[0m and \u001b[32m'Tensor'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_.grad  / grad_norms[0] ** gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e294d07-ea0b-475b-b4dc-25a1e7dd00b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([class_label], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74ccc006-4a9f-4777-9a32-9cac55ad1b2d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]]]], device='cuda:0',\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5ad00bd-b3a8-47f7-acfd-523339c311aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_past = list(map(add, past, curr_perturbation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1c9c6c1-a886-40e5-82bd-87d54ca77602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4096])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(curr_hidden, dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0d432fe-170d-4d7c-ac4a-12a0e309bc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 32, 3, 128])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturbed_past[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ebb26d0-142a-4a5d-b4e6-f7ea906bf0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7582, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "337fcff6-7b9a-4fa8-847f-677b0c68a996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32000])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>all_logits, all_hidden = lm_output[<span style=\"color: #808000; text-decoration-color: #808000\">\"logits\"</span>], lm_output[<span style=\"color: #808000; text-decoration-color: #808000\">\"hidden_states\"</span>]                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(all_logits.shape)                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>7 <span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(all_hidden.shape)                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'tuple'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'shape'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m7\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0mall_logits, all_hidden = lm_output[\u001b[33m\"\u001b[0m\u001b[33mlogits\u001b[0m\u001b[33m\"\u001b[0m], lm_output[\u001b[33m\"\u001b[0m\u001b[33mhidden_states\u001b[0m\u001b[33m\"\u001b[0m]                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[96mprint\u001b[0m(all_logits.shape)                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m7 \u001b[96mprint\u001b[0m(all_hidden.shape)                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m8 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'tuple'\u001b[0m object has no attribute \u001b[32m'shape'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(perturbed_past)):\n",
    "        perturbed_past[i] = perturbed_past[i].to(torch.float16)\n",
    "lm_output = model(last, past_key_values=perturbed_past,return_dict =True,output_hidden_states=True)\n",
    "\n",
    "all_logits, all_hidden = lm_output[\"logits\"], lm_output[\"hidden_states\"]\n",
    "print(all_logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ff15add-552f-4d2d-980b-7e66f233cc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 torch.Size([1, 1, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(len(all_hidden),all_hidden[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2109cfc2-a89f-4d0a-bb60-bdb69f23ebd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4096])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = all_hidden[-1]\n",
    "a= torch.sum(hidden, dim=1)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e6c2f-0ff3-45eb-b2f8-016544c3a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hidden = all_hidden[-1]\n",
    "new_accumulated_hidden = accumulated_hidden + torch.sum(hidden, dim=1).detach()\n",
    "# TODO: Check the layer-norm consistency of this with trained discriminator (Sumanth)\n",
    "logits = all_logits[:, -1, :]\n",
    "probs = nn.functional.softmax(logits, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c9cd7ca-6bbf-4c1b-a3f8-39e761a00cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6cd8b591-a81f-4023-afad-9ed7e64705c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_length + 1 + horizon_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "75e8ce09-5229-4e22-bed4-fd75e9d0f2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4238,  3.9180, -3.2617,  ..., -2.1250,  4.5234,  8.4609]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_accumulated_hidden/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d71eae0-960d-4107-aefc-e4296dde46ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4096])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_accumulated_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49a3c399-e792-4c5d-97ce-b36cd0efd98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2424,  0.3918, -0.3262,  ..., -0.2125,  0.4524,  0.8462]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_accumulated_hidden/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d79c0769-0070-4b86-989e-cb67c2db8f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffdeec6e-3109-470c-9163-a9bd85c02adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2], device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(prediction.shape[0] * [class_label], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce267b2f-3c44-4c14-8957-83bcddedc35e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mh",
   "language": "python",
   "name": "mh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
